type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [205 129]]
Accuracy (<> F measure = f1score) is :  0.6791862284820032
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.60      1.00      0.75       305
           1       1.00      0.39      0.56       334

    accuracy                           0.68       639
   macro avg       0.80      0.69      0.65       639
weighted avg       0.81      0.68      0.65       639

F measure at 0 is :  0.7484662576687116
F measure at 1 is :  0.5572354211663068
------------ end testing the model ------------
start clf.fit at :2019-12-09 05:58:11.219421
end clf.fit at :2019-12-09 05:58:11.219495
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.661856347847358
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [220 114]]
Accuracy (<> F measure = f1score) is :  0.6557120500782473
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.58      1.00      0.73       305
           1       1.00      0.34      0.51       334

    accuracy                           0.66       639
   macro avg       0.79      0.67      0.62       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7349397590361446
F measure at 1 is :  0.5089285714285715
------------ end testing the model ------------
start clf.fit at :2019-12-09 05:58:11.244875
end clf.fit at :2019-12-09 05:58:11.249119
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6602915545499022
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 117]]
Accuracy (<> F measure = f1score) is :  0.6619718309859155
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       333

    accuracy                           0.66       639
   macro avg       0.79      0.68      0.63       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.52
------------ end testing the model ------------
overall_accuracy:  0.6605131414267835
overall_f_measure:  0.5184198845983133
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  kr-vs-kp.arff-ratio-0.6-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (3196, 4)
dataset.head(5):              0             1             2  3
0  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
1  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
2  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
3  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
4  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
X_binary.shape:  (3196, 6)
start clf.fit at :2019-12-09 05:58:11.360531
end clf.fit at :2019-12-09 05:58:29.493240
clf.best_params:  {'C': 0.03125, 'gamma': 0.5, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9061322773972602
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[256  50]
 [ 16 318]]
Accuracy (<> F measure = f1score) is :  0.896875
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.94      0.84      0.89       306
           1       0.86      0.95      0.91       334

    accuracy                           0.90       640
   macro avg       0.90      0.89      0.90       640
weighted avg       0.90      0.90      0.90       640

F measure at 0 is :  0.8858131487889274
F measure at 1 is :  0.905982905982906
------------ end testing the model ------------
start clf.fit at :2019-12-09 05:58:29.534733
end clf.fit at :2019-12-09 05:58:47.627431
clf.best_params:  {'C': 0.03125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9049726333170256
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[251  54]
 [  9 325]]
Accuracy (<> F measure = f1score) is :  0.9014084507042254
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.82      0.89       305
           1       0.86      0.97      0.91       334

    accuracy                           0.90       639
   macro avg       0.91      0.90      0.90       639
weighted avg       0.91      0.90      0.90       639

F measure at 0 is :  0.8884955752212388
F measure at 1 is :  0.9116409537166901
------------ end testing the model ------------
start clf.fit at :2019-12-09 05:58:47.697454
end clf.fit at :2019-12-09 05:59:05.745000
clf.best_params:  {'C': 0.03125, 'gamma': 0.5, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9034078400195694
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[255  50]
 [  9 325]]
Accuracy (<> F measure = f1score) is :  0.9076682316118936
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.84      0.90       305
           1       0.87      0.97      0.92       334

    accuracy                           0.91       639
   macro avg       0.92      0.90      0.91       639
weighted avg       0.91      0.91      0.91       639

F measure at 0 is :  0.8963093145869947
F measure at 1 is :  0.9167842031029619
------------ end testing the model ------------
start clf.fit at :2019-12-09 05:59:05.792739
end clf.fit at :2019-12-09 05:59:23.832393
clf.best_params:  {'C': 0.03125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9045843016144814
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[251  54]
 [  8 326]]
Accuracy (<> F measure = f1score) is :  0.9029733959311425
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.82      0.89       305
           1       0.86      0.98      0.91       334

    accuracy                           0.90       639
   macro avg       0.91      0.90      0.90       639
weighted avg       0.91      0.90      0.90       639

F measure at 0 is :  0.8900709219858155
F measure at 1 is :  0.9131652661064426
------------ end testing the model ------------
start clf.fit at :2019-12-09 05:59:23.916397
end clf.fit at :2019-12-09 05:59:42.221087
clf.best_params:  {'C': 0.03125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9022397871819962
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[254  52]
 [  4 329]]
Accuracy (<> F measure = f1score) is :  0.9123630672926447
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.98      0.83      0.90       306
           1       0.86      0.99      0.92       333

    accuracy                           0.91       639
   macro avg       0.92      0.91      0.91       639
weighted avg       0.92      0.91      0.91       639

F measure at 0 is :  0.900709219858156
F measure at 1 is :  0.9215686274509803
------------ end testing the model ------------
overall_accuracy:  0.9042553191489362
overall_f_measure:  0.9138513513513513
start clf.fit at :2019-12-09 05:59:42.312934
end clf.fit at :2019-12-09 05:59:42.312934
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6600866866438355
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 118]]
Accuracy (<> F measure = f1score) is :  0.6625
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       334

    accuracy                           0.66       640
   macro avg       0.79      0.68      0.63       640
weighted avg       0.80      0.66      0.63       640

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.5221238938053098
------------ end testing the model ------------
start clf.fit at :2019-12-09 05:59:42.344459
end clf.fit at :2019-12-09 05:59:42.355115
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6649874633072408
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [228 106]]
Accuracy (<> F measure = f1score) is :  0.6431924882629108
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.57      1.00      0.73       305
           1       1.00      0.32      0.48       334

    accuracy                           0.64       639
   macro avg       0.79      0.66      0.60       639
weighted avg       0.80      0.64      0.60       639

F measure at 0 is :  0.7279236276849643
F measure at 1 is :  0.48181818181818187
------------ end testing the model ------------
start clf.fit at :2019-12-09 05:59:42.384154
end clf.fit at :2019-12-09 05:59:42.392330
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6559855063600782
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [205 129]]
Accuracy (<> F measure = f1score) is :  0.6791862284820032
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.60      1.00      0.75       305
           1       1.00      0.39      0.56       334

    accuracy                           0.68       639
   macro avg       0.80      0.69      0.65       639
weighted avg       0.81      0.68      0.65       639

F measure at 0 is :  0.7484662576687116
F measure at 1 is :  0.5572354211663068
------------ end testing the model ------------
start clf.fit at :2019-12-09 05:59:42.426117
end clf.fit at :2019-12-09 05:59:42.426117
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.661856347847358
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [220 114]]
Accuracy (<> F measure = f1score) is :  0.6557120500782473
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.58      1.00      0.73       305
           1       1.00      0.34      0.51       334

    accuracy                           0.66       639
   macro avg       0.79      0.67      0.62       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7349397590361446
F measure at 1 is :  0.5089285714285715
------------ end testing the model ------------
start clf.fit at :2019-12-09 05:59:42.462573
end clf.fit at :2019-12-09 05:59:42.463281
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6602915545499022
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 117]]
Accuracy (<> F measure = f1score) is :  0.6619718309859155
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       333

    accuracy                           0.66       639
   macro avg       0.79      0.68      0.63       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.52
------------ end testing the model ------------
overall_accuracy:  0.6605131414267835
overall_f_measure:  0.5184198845983133
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  kr-vs-kp.arff-ratio-0.7-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (3196, 5)
dataset.head(5):              0             1             2             3  4
0  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
1  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
2  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
3  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
4  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
X_binary.shape:  (3196, 8)
start clf.fit at :2019-12-09 05:59:42.611253
end clf.fit at :2019-12-09 05:59:59.632599
clf.best_params:  {'C': 0.125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.945653436888454
clf.best_estimator_:  SVC(C=0.125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[275  31]
 [ 19 315]]
Accuracy (<> F measure = f1score) is :  0.921875
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.94      0.90      0.92       306
           1       0.91      0.94      0.93       334

    accuracy                           0.92       640
   macro avg       0.92      0.92      0.92       640
weighted avg       0.92      0.92      0.92       640

F measure at 0 is :  0.9166666666666667
F measure at 1 is :  0.9264705882352942
------------ end testing the model ------------
start clf.fit at :2019-12-09 05:59:59.681817
end clf.fit at :2019-12-09 06:00:16.874733
clf.best_params:  {'C': 0.03125, 'gamma': 2, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9397948263209394
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf', max_iter=-1,
    probability=False, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[279  26]
 [  9 325]]
Accuracy (<> F measure = f1score) is :  0.945226917057903
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.91      0.94       305
           1       0.93      0.97      0.95       334

    accuracy                           0.95       639
   macro avg       0.95      0.94      0.94       639
weighted avg       0.95      0.95      0.95       639

F measure at 0 is :  0.9409780775716694
F measure at 1 is :  0.9489051094890512
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:00:16.931428
end clf.fit at :2019-12-09 06:00:33.890582
clf.best_params:  {'C': 0.03125, 'gamma': 2, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9413619129158514
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf', max_iter=-1,
    probability=False, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[275  30]
 [  9 325]]
Accuracy (<> F measure = f1score) is :  0.9389671361502347
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.90      0.93       305
           1       0.92      0.97      0.94       334

    accuracy                           0.94       639
   macro avg       0.94      0.94      0.94       639
weighted avg       0.94      0.94      0.94       639

F measure at 0 is :  0.933786078098472
F measure at 1 is :  0.9433962264150942
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:00:33.944677
end clf.fit at :2019-12-09 06:00:51.087021
clf.best_params:  {'C': 0.03125, 'gamma': 2, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9405829562133073
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf', max_iter=-1,
    probability=False, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[276  29]
 [  8 326]]
Accuracy (<> F measure = f1score) is :  0.9420970266040689
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.90      0.94       305
           1       0.92      0.98      0.95       334

    accuracy                           0.94       639
   macro avg       0.95      0.94      0.94       639
weighted avg       0.94      0.94      0.94       639

F measure at 0 is :  0.937181663837012
F measure at 1 is :  0.9462989840348331
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:00:51.150844
end clf.fit at :2019-12-09 06:01:08.521503
clf.best_params:  {'C': 0.03125, 'gamma': 2, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9370650379158512
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf', max_iter=-1,
    probability=False, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[282  24]
 [  4 329]]
Accuracy (<> F measure = f1score) is :  0.9561815336463224
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.99      0.92      0.95       306
           1       0.93      0.99      0.96       333

    accuracy                           0.96       639
   macro avg       0.96      0.95      0.96       639
weighted avg       0.96      0.96      0.96       639

F measure at 0 is :  0.9527027027027026
F measure at 1 is :  0.9591836734693878
------------ end testing the model ------------
overall_accuracy:  0.940863579474343
overall_f_measure:  0.9448818897637795
start clf.fit at :2019-12-09 06:01:08.590613
end clf.fit at :2019-12-09 06:01:08.591290
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6600866866438355
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 118]]
Accuracy (<> F measure = f1score) is :  0.6625
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       334

    accuracy                           0.66       640
   macro avg       0.79      0.68      0.63       640
weighted avg       0.80      0.66      0.63       640

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.5221238938053098
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:01:08.626227
end clf.fit at :2019-12-09 06:01:08.626585
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6649874633072408
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [228 106]]
Accuracy (<> F measure = f1score) is :  0.6431924882629108
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.57      1.00      0.73       305
           1       1.00      0.32      0.48       334

    accuracy                           0.64       639
   macro avg       0.79      0.66      0.60       639
weighted avg       0.80      0.64      0.60       639

F measure at 0 is :  0.7279236276849643
F measure at 1 is :  0.48181818181818187
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:01:08.655039
end clf.fit at :2019-12-09 06:01:08.670692
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6559855063600782
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [205 129]]
Accuracy (<> F measure = f1score) is :  0.6791862284820032
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.60      1.00      0.75       305
           1       1.00      0.39      0.56       334

    accuracy                           0.68       639
   macro avg       0.80      0.69      0.65       639
weighted avg       0.81      0.68      0.65       639

F measure at 0 is :  0.7484662576687116
F measure at 1 is :  0.5572354211663068
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:01:08.701672
end clf.fit at :2019-12-09 06:01:08.701844
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.661856347847358
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [220 114]]
Accuracy (<> F measure = f1score) is :  0.6557120500782473
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.58      1.00      0.73       305
           1       1.00      0.34      0.51       334

    accuracy                           0.66       639
   macro avg       0.79      0.67      0.62       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7349397590361446
F measure at 1 is :  0.5089285714285715
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:01:08.735129
end clf.fit at :2019-12-09 06:01:08.738253
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6602915545499022
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 117]]
Accuracy (<> F measure = f1score) is :  0.6619718309859155
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       333

    accuracy                           0.66       639
   macro avg       0.79      0.68      0.63       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.52
------------ end testing the model ------------
overall_accuracy:  0.6605131414267835
overall_f_measure:  0.5184198845983133
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  kr-vs-kp.arff-ratio-0.8-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (3196, 9)
dataset.head(5):             0             1             2             3             4             5             6             7  8
0  '(0.9-inf)'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
1  '(0.9-inf)'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
2  '(0.9-inf)'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
3  '(0.9-inf)'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
4  '(0.9-inf)'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
X_binary.shape:  (3196, 17)
start clf.fit at :2019-12-09 06:01:08.933106
end clf.fit at :2019-12-09 06:01:40.272193
clf.best_params:  {'C': 0.5, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.945653436888454
clf.best_estimator_:  SVC(C=0.5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[275  31]
 [ 19 315]]
Accuracy (<> F measure = f1score) is :  0.921875
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.94      0.90      0.92       306
           1       0.91      0.94      0.93       334

    accuracy                           0.92       640
   macro avg       0.92      0.92      0.92       640
weighted avg       0.92      0.92      0.92       640

F measure at 0 is :  0.9166666666666667
F measure at 1 is :  0.9264705882352942
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:01:40.333392
end clf.fit at :2019-12-09 06:02:12.529006
clf.best_params:  {'C': 0.125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9390120474559687
clf.best_estimator_:  SVC(C=0.125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[279  26]
 [  9 325]]
Accuracy (<> F measure = f1score) is :  0.945226917057903
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.91      0.94       305
           1       0.93      0.97      0.95       334

    accuracy                           0.95       639
   macro avg       0.95      0.94      0.94       639
weighted avg       0.95      0.95      0.95       639

F measure at 0 is :  0.9409780775716694
F measure at 1 is :  0.9489051094890512
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:02:12.596545
end clf.fit at :2019-12-09 06:02:43.883523
clf.best_params:  {'C': 512, 'gamma': 0.001953125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.93979635518591
clf.best_estimator_:  SVC(C=512, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.001953125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[275  30]
 [  9 325]]
Accuracy (<> F measure = f1score) is :  0.9389671361502347
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.90      0.93       305
           1       0.92      0.97      0.94       334

    accuracy                           0.94       639
   macro avg       0.94      0.94      0.94       639
weighted avg       0.94      0.94      0.94       639

F measure at 0 is :  0.933786078098472
F measure at 1 is :  0.9433962264150942
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:02:43.911498
end clf.fit at :2019-12-09 06:03:16.675818
clf.best_params:  {'C': 0.5, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9405829562133073
clf.best_estimator_:  SVC(C=0.5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[276  29]
 [  8 326]]
Accuracy (<> F measure = f1score) is :  0.9420970266040689
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.90      0.94       305
           1       0.92      0.98      0.95       334

    accuracy                           0.94       639
   macro avg       0.95      0.94      0.94       639
weighted avg       0.94      0.94      0.94       639

F measure at 0 is :  0.937181663837012
F measure at 1 is :  0.9462989840348331
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:03:16.721072
end clf.fit at :2019-12-09 06:03:49.226505
clf.best_params:  {'C': 0.5, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9370650379158512
clf.best_estimator_:  SVC(C=0.5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[282  24]
 [  4 329]]
Accuracy (<> F measure = f1score) is :  0.9561815336463224
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.99      0.92      0.95       306
           1       0.93      0.99      0.96       333

    accuracy                           0.96       639
   macro avg       0.96      0.95      0.96       639
weighted avg       0.96      0.96      0.96       639

F measure at 0 is :  0.9527027027027026
F measure at 1 is :  0.9591836734693878
------------ end testing the model ------------
overall_accuracy:  0.940863579474343
overall_f_measure:  0.9448818897637795
start clf.fit at :2019-12-09 06:03:49.296042
end clf.fit at :2019-12-09 06:03:49.296713
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6600866866438355
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 118]]
Accuracy (<> F measure = f1score) is :  0.6625
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       334

    accuracy                           0.66       640
   macro avg       0.79      0.68      0.63       640
weighted avg       0.80      0.66      0.63       640

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.5221238938053098
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:03:49.327690
end clf.fit at :2019-12-09 06:03:49.343632
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6649874633072408
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [228 106]]
Accuracy (<> F measure = f1score) is :  0.6431924882629108
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.57      1.00      0.73       305
           1       1.00      0.32      0.48       334

    accuracy                           0.64       639
   macro avg       0.79      0.66      0.60       639
weighted avg       0.80      0.64      0.60       639

F measure at 0 is :  0.7279236276849643
F measure at 1 is :  0.48181818181818187
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:03:49.366686
end clf.fit at :2019-12-09 06:03:49.366686
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6559855063600782
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [205 129]]
Accuracy (<> F measure = f1score) is :  0.6791862284820032
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.60      1.00      0.75       305
           1       1.00      0.39      0.56       334

    accuracy                           0.68       639
   macro avg       0.80      0.69      0.65       639
weighted avg       0.81      0.68      0.65       639

F measure at 0 is :  0.7484662576687116
F measure at 1 is :  0.5572354211663068
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:03:49.401276
end clf.fit at :2019-12-09 06:03:49.413439
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.661856347847358
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [220 114]]
Accuracy (<> F measure = f1score) is :  0.6557120500782473
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.58      1.00      0.73       305
           1       1.00      0.34      0.51       334

    accuracy                           0.66       639
   macro avg       0.79      0.67      0.62       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7349397590361446
F measure at 1 is :  0.5089285714285715
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:03:49.443465
end clf.fit at :2019-12-09 06:03:49.459253
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6602915545499022
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 117]]
Accuracy (<> F measure = f1score) is :  0.6619718309859155
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       333

    accuracy                           0.66       639
   macro avg       0.79      0.68      0.63       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.52
------------ end testing the model ------------
overall_accuracy:  0.6605131414267835
overall_f_measure:  0.5184198845983133
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  kr-vs-kp.arff-ratio-0.9-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (3196, 12)
dataset.head(5):              0             1            2            3             4             5             6             7             8             9            10 11
0  '(-inf-0.1]'  '(-inf-0.1]'  '(0.9-inf)'  '(0.9-inf)'  '(-inf-0.1]'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
1  '(-inf-0.1]'  '(-inf-0.1]'  '(0.9-inf)'  '(0.9-inf)'  '(-inf-0.1]'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
2  '(-inf-0.1]'  '(-inf-0.1]'  '(0.9-inf)'  '(0.9-inf)'   '(0.9-inf)'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
3  '(-inf-0.1]'  '(-inf-0.1]'  '(0.9-inf)'  '(0.9-inf)'  '(-inf-0.1]'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
4  '(-inf-0.1]'  '(-inf-0.1]'  '(0.9-inf)'  '(0.9-inf)'  '(-inf-0.1]'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
X_binary.shape:  (3196, 23)
start clf.fit at :2019-12-09 06:03:49.677703
end clf.fit at :2019-12-09 06:04:28.260832
clf.best_params:  {'C': 0.5, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9409567636986301
clf.best_estimator_:  SVC(C=0.5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[299   7]
 [ 27 307]]
Accuracy (<> F measure = f1score) is :  0.946875
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.92      0.98      0.95       306
           1       0.98      0.92      0.95       334

    accuracy                           0.95       640
   macro avg       0.95      0.95      0.95       640
weighted avg       0.95      0.95      0.95       640

F measure at 0 is :  0.9462025316455697
F measure at 1 is :  0.9475308641975307
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:04:28.305832
end clf.fit at :2019-12-09 06:05:07.081727
clf.best_params:  {'C': 0.5, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9331412059686889
clf.best_estimator_:  SVC(C=0.5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[279  26]
 [ 11 323]]
Accuracy (<> F measure = f1score) is :  0.9420970266040689
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.96      0.91      0.94       305
           1       0.93      0.97      0.95       334

    accuracy                           0.94       639
   macro avg       0.94      0.94      0.94       639
weighted avg       0.94      0.94      0.94       639

F measure at 0 is :  0.9378151260504202
F measure at 1 is :  0.9458272327964862
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:05:07.161954
end clf.fit at :2019-12-09 06:05:46.652691
clf.best_params:  {'C': 0.125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9319685665362035
clf.best_estimator_:  SVC(C=0.125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[276  29]
 [  9 325]]
Accuracy (<> F measure = f1score) is :  0.9405320813771518
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.90      0.94       305
           1       0.92      0.97      0.94       334

    accuracy                           0.94       639
   macro avg       0.94      0.94      0.94       639
weighted avg       0.94      0.94      0.94       639

F measure at 0 is :  0.9355932203389831
F measure at 1 is :  0.944767441860465
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:05:46.749847
end clf.fit at :2019-12-09 06:06:25.296638
clf.best_params:  {'C': 32, 'gamma': 0.001953125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9382346196183953
clf.best_estimator_:  SVC(C=32, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.001953125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[276  29]
 [ 10 324]]
Accuracy (<> F measure = f1score) is :  0.9389671361502347
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.90      0.93       305
           1       0.92      0.97      0.94       334

    accuracy                           0.94       639
   macro avg       0.94      0.94      0.94       639
weighted avg       0.94      0.94      0.94       639

F measure at 0 is :  0.934010152284264
F measure at 1 is :  0.9432314410480349
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:06:25.338643
end clf.fit at :2019-12-09 06:07:04.078051
clf.best_params:  {'C': 0.125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9280630809686888
clf.best_estimator_:  SVC(C=0.125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[283  23]
 [  4 329]]
Accuracy (<> F measure = f1score) is :  0.9577464788732394
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.99      0.92      0.95       306
           1       0.93      0.99      0.96       333

    accuracy                           0.96       639
   macro avg       0.96      0.96      0.96       639
weighted avg       0.96      0.96      0.96       639

F measure at 0 is :  0.954468802698145
F measure at 1 is :  0.9605839416058394
------------ end testing the model ------------
overall_accuracy:  0.945244055068836
overall_f_measure:  0.9483928044824536
start clf.fit at :2019-12-09 06:07:04.156138
end clf.fit at :2019-12-09 06:07:04.156138
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6600866866438355
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 118]]
Accuracy (<> F measure = f1score) is :  0.6625
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       334

    accuracy                           0.66       640
   macro avg       0.79      0.68      0.63       640
weighted avg       0.80      0.66      0.63       640

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.5221238938053098
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:07:04.190874
end clf.fit at :2019-12-09 06:07:04.191213
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6649874633072408
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [228 106]]
Accuracy (<> F measure = f1score) is :  0.6431924882629108
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.57      1.00      0.73       305
           1       1.00      0.32      0.48       334

    accuracy                           0.64       639
   macro avg       0.79      0.66      0.60       639
weighted avg       0.80      0.64      0.60       639

F measure at 0 is :  0.7279236276849643
F measure at 1 is :  0.48181818181818187
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:07:04.226689
end clf.fit at :2019-12-09 06:07:04.242354
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6559855063600782
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [205 129]]
Accuracy (<> F measure = f1score) is :  0.6791862284820032
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.60      1.00      0.75       305
           1       1.00      0.39      0.56       334

    accuracy                           0.68       639
   macro avg       0.80      0.69      0.65       639
weighted avg       0.81      0.68      0.65       639

F measure at 0 is :  0.7484662576687116
F measure at 1 is :  0.5572354211663068
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:07:04.278212
end clf.fit at :2019-12-09 06:07:04.293869
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.661856347847358
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [220 114]]
Accuracy (<> F measure = f1score) is :  0.6557120500782473
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.58      1.00      0.73       305
           1       1.00      0.34      0.51       334

    accuracy                           0.66       639
   macro avg       0.79      0.67      0.62       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7349397590361446
F measure at 1 is :  0.5089285714285715
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:07:04.330051
end clf.fit at :2019-12-09 06:07:04.345766
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6602915545499022
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 117]]
Accuracy (<> F measure = f1score) is :  0.6619718309859155
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       333

    accuracy                           0.66       639
   macro avg       0.79      0.68      0.63       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.52
------------ end testing the model ------------
overall_accuracy:  0.6605131414267835
overall_f_measure:  0.5184198845983133
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  kr-vs-kp.arff-ratio-1.0-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (3196, 33)
dataset.head(5):             0             1             2             3             4             5   ...            27            28            29            30            31 32
0  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.3]'  ...  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
1  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.3]'  ...  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
2  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.3]'  ...  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
3  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.3]'  ...  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
4  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.3]'  ...  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1

[5 rows x 33 columns]
X_binary.shape:  (3196, 65)
start clf.fit at :2019-12-09 06:07:04.879233
end clf.fit at :2019-12-09 06:08:59.377853
clf.best_params:  {'C': 32, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.967928999510763
clf.best_estimator_:  SVC(C=32, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[300   6]
 [  9 325]]
Accuracy (<> F measure = f1score) is :  0.9765625
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.98      0.98       306
           1       0.98      0.97      0.98       334

    accuracy                           0.98       640
   macro avg       0.98      0.98      0.98       640
weighted avg       0.98      0.98      0.98       640

F measure at 0 is :  0.975609756097561
F measure at 1 is :  0.9774436090225564
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:08:59.419917
end clf.fit at :2019-12-09 06:10:52.640195
clf.best_params:  {'C': 512, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9690970523483365
clf.best_estimator_:  SVC(C=512, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[299   6]
 [  5 329]]
Accuracy (<> F measure = f1score) is :  0.9827856025039123
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.98      0.98      0.98       305
           1       0.98      0.99      0.98       334

    accuracy                           0.98       639
   macro avg       0.98      0.98      0.98       639
weighted avg       0.98      0.98      0.98       639

F measure at 0 is :  0.9819376026272578
F measure at 1 is :  0.9835575485799701
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:10:52.662269
end clf.fit at :2019-12-09 06:12:46.450260
clf.best_params:  {'C': 512, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9647925330234834
clf.best_estimator_:  SVC(C=512, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[304   1]
 [  4 330]]
Accuracy (<> F measure = f1score) is :  0.9921752738654147
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.99      1.00      0.99       305
           1       1.00      0.99      0.99       334

    accuracy                           0.99       639
   macro avg       0.99      0.99      0.99       639
weighted avg       0.99      0.99      0.99       639

F measure at 0 is :  0.9918433931484504
F measure at 1 is :  0.9924812030075189
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:12:46.478044
end clf.fit at :2019-12-09 06:14:40.742258
clf.best_params:  {'C': 32, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9706610812133073
clf.best_estimator_:  SVC(C=32, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[301   4]
 [  5 329]]
Accuracy (<> F measure = f1score) is :  0.9859154929577465
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.98      0.99      0.99       305
           1       0.99      0.99      0.99       334

    accuracy                           0.99       639
   macro avg       0.99      0.99      0.99       639
weighted avg       0.99      0.99      0.99       639

F measure at 0 is :  0.9852700490998363
F measure at 1 is :  0.9865067466266867
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:14:40.781494
end clf.fit at :2019-12-09 06:16:35.504236
clf.best_params:  {'C': 512, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9577490521037182
clf.best_estimator_:  SVC(C=512, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[302   4]
 [  3 330]]
Accuracy (<> F measure = f1score) is :  0.9890453834115805
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.99      0.99      0.99       306
           1       0.99      0.99      0.99       333

    accuracy                           0.99       639
   macro avg       0.99      0.99      0.99       639
weighted avg       0.99      0.99      0.99       639

F measure at 0 is :  0.9885433715220949
F measure at 1 is :  0.9895052473763118
------------ end testing the model ------------
overall_accuracy:  0.9852941176470589
overall_f_measure:  0.9858985898589859
start clf.fit at :2019-12-09 06:16:35.522026
end clf.fit at :2019-12-09 06:16:35.553797
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6393101761252445
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 88 218]
 [ 11 323]]
Accuracy (<> F measure = f1score) is :  0.6421875
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.89      0.29      0.43       306
           1       0.60      0.97      0.74       334

    accuracy                           0.64       640
   macro avg       0.74      0.63      0.59       640
weighted avg       0.74      0.64      0.59       640

F measure at 0 is :  0.43456790123456795
F measure at 1 is :  0.7382857142857142
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:16:35.553797
end clf.fit at :2019-12-09 06:16:35.585276
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6332352311643836
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 47 258]
 [  2 332]]
Accuracy (<> F measure = f1score) is :  0.593114241001565
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.96      0.15      0.27       305
           1       0.56      0.99      0.72       334

    accuracy                           0.59       639
   macro avg       0.76      0.57      0.49       639
weighted avg       0.75      0.59      0.50       639

F measure at 0 is :  0.26553672316384175
F measure at 1 is :  0.7186147186147186
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:16:35.585276
end clf.fit at :2019-12-09 06:16:35.616516
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6332359955968688
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 61 244]
 [  0 334]]
Accuracy (<> F measure = f1score) is :  0.6181533646322379
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       1.00      0.20      0.33       305
           1       0.58      1.00      0.73       334

    accuracy                           0.62       639
   macro avg       0.79      0.60      0.53       639
weighted avg       0.78      0.62      0.54       639

F measure at 0 is :  0.33333333333333337
F measure at 1 is :  0.7324561403508771
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:16:35.635232
end clf.fit at :2019-12-09 06:16:35.651023
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6187553510273973
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 67 238]
 [  0 334]]
Accuracy (<> F measure = f1score) is :  0.6275430359937402
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       1.00      0.22      0.36       305
           1       0.58      1.00      0.74       334

    accuracy                           0.63       639
   macro avg       0.79      0.61      0.55       639
weighted avg       0.78      0.63      0.56       639

F measure at 0 is :  0.3602150537634409
F measure at 1 is :  0.7373068432671082
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:16:35.651023
end clf.fit at :2019-12-09 06:16:35.666644
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6289268896771036
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 70 236]
 [  0 333]]
Accuracy (<> F measure = f1score) is :  0.6306729264475743
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       1.00      0.23      0.37       306
           1       0.59      1.00      0.74       333

    accuracy                           0.63       639
   macro avg       0.79      0.61      0.56       639
weighted avg       0.78      0.63      0.56       639

F measure at 0 is :  0.3723404255319149
F measure at 1 is :  0.738359201773836
------------ end testing the model ------------
overall_accuracy:  0.6223404255319149
overall_f_measure:  0.7329055100685993
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  kr-vs-kp.arff-relevance-0.5-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (3196, 4)
dataset.head(5):              0             1             2  3
0  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
1  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
2  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
3  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
4  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
X_binary.shape:  (3196, 6)
start clf.fit at :2019-12-09 06:16:35.764732
end clf.fit at :2019-12-09 06:16:54.064142
clf.best_params:  {'C': 0.03125, 'gamma': 0.5, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9061322773972602
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[256  50]
 [ 16 318]]
Accuracy (<> F measure = f1score) is :  0.896875
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.94      0.84      0.89       306
           1       0.86      0.95      0.91       334

    accuracy                           0.90       640
   macro avg       0.90      0.89      0.90       640
weighted avg       0.90      0.90      0.90       640

F measure at 0 is :  0.8858131487889274
F measure at 1 is :  0.905982905982906
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:16:54.095393
end clf.fit at :2019-12-09 06:17:12.170109
clf.best_params:  {'C': 0.03125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9049726333170256
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[251  54]
 [  9 325]]
Accuracy (<> F measure = f1score) is :  0.9014084507042254
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.82      0.89       305
           1       0.86      0.97      0.91       334

    accuracy                           0.90       639
   macro avg       0.91      0.90      0.90       639
weighted avg       0.91      0.90      0.90       639

F measure at 0 is :  0.8884955752212388
F measure at 1 is :  0.9116409537166901
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:17:12.201352
end clf.fit at :2019-12-09 06:17:30.226210
clf.best_params:  {'C': 0.03125, 'gamma': 0.5, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9034078400195694
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[255  50]
 [  9 325]]
Accuracy (<> F measure = f1score) is :  0.9076682316118936
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.84      0.90       305
           1       0.87      0.97      0.92       334

    accuracy                           0.91       639
   macro avg       0.92      0.90      0.91       639
weighted avg       0.91      0.91      0.91       639

F measure at 0 is :  0.8963093145869947
F measure at 1 is :  0.9167842031029619
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:17:30.257588
end clf.fit at :2019-12-09 06:17:48.299910
clf.best_params:  {'C': 0.03125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9045843016144814
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[251  54]
 [  8 326]]
Accuracy (<> F measure = f1score) is :  0.9029733959311425
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.82      0.89       305
           1       0.86      0.98      0.91       334

    accuracy                           0.90       639
   macro avg       0.91      0.90      0.90       639
weighted avg       0.91      0.90      0.90       639

F measure at 0 is :  0.8900709219858155
F measure at 1 is :  0.9131652661064426
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:17:48.342476
end clf.fit at :2019-12-09 06:18:06.527357
clf.best_params:  {'C': 0.03125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9022397871819962
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[254  52]
 [  4 329]]
Accuracy (<> F measure = f1score) is :  0.9123630672926447
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.98      0.83      0.90       306
           1       0.86      0.99      0.92       333

    accuracy                           0.91       639
   macro avg       0.92      0.91      0.91       639
weighted avg       0.92      0.91      0.91       639

F measure at 0 is :  0.900709219858156
F measure at 1 is :  0.9215686274509803
------------ end testing the model ------------
overall_accuracy:  0.9042553191489362
overall_f_measure:  0.9138513513513513
start clf.fit at :2019-12-09 06:18:06.562785
end clf.fit at :2019-12-09 06:18:06.562785
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6600866866438355
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 118]]
Accuracy (<> F measure = f1score) is :  0.6625
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       334

    accuracy                           0.66       640
   macro avg       0.79      0.68      0.63       640
weighted avg       0.80      0.66      0.63       640

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.5221238938053098
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:18:06.578409
end clf.fit at :2019-12-09 06:18:06.578409
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6649874633072408
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [228 106]]
Accuracy (<> F measure = f1score) is :  0.6431924882629108
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.57      1.00      0.73       305
           1       1.00      0.32      0.48       334

    accuracy                           0.64       639
   macro avg       0.79      0.66      0.60       639
weighted avg       0.80      0.64      0.60       639

F measure at 0 is :  0.7279236276849643
F measure at 1 is :  0.48181818181818187
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:18:06.594027
end clf.fit at :2019-12-09 06:18:06.594027
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6559855063600782
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [205 129]]
Accuracy (<> F measure = f1score) is :  0.6791862284820032
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.60      1.00      0.75       305
           1       1.00      0.39      0.56       334

    accuracy                           0.68       639
   macro avg       0.80      0.69      0.65       639
weighted avg       0.81      0.68      0.65       639

F measure at 0 is :  0.7484662576687116
F measure at 1 is :  0.5572354211663068
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:18:06.609648
end clf.fit at :2019-12-09 06:18:06.609648
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.661856347847358
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [220 114]]
Accuracy (<> F measure = f1score) is :  0.6557120500782473
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.58      1.00      0.73       305
           1       1.00      0.34      0.51       334

    accuracy                           0.66       639
   macro avg       0.79      0.67      0.62       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7349397590361446
F measure at 1 is :  0.5089285714285715
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:18:06.625269
end clf.fit at :2019-12-09 06:18:06.625269
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6602915545499022
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 117]]
Accuracy (<> F measure = f1score) is :  0.6619718309859155
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       333

    accuracy                           0.66       639
   macro avg       0.79      0.68      0.63       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.52
------------ end testing the model ------------
overall_accuracy:  0.6605131414267835
overall_f_measure:  0.5184198845983133
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  kr-vs-kp.arff-relevance-0.6-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (3196, 4)
dataset.head(5):              0             1             2  3
0  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
1  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
2  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
3  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
4  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
X_binary.shape:  (3196, 6)
start clf.fit at :2019-12-09 06:18:06.723626
end clf.fit at :2019-12-09 06:18:24.819993
clf.best_params:  {'C': 0.03125, 'gamma': 0.5, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9061322773972602
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[256  50]
 [ 16 318]]
Accuracy (<> F measure = f1score) is :  0.896875
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.94      0.84      0.89       306
           1       0.86      0.95      0.91       334

    accuracy                           0.90       640
   macro avg       0.90      0.89      0.90       640
weighted avg       0.90      0.90      0.90       640

F measure at 0 is :  0.8858131487889274
F measure at 1 is :  0.905982905982906
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:18:24.835617
end clf.fit at :2019-12-09 06:18:42.838866
clf.best_params:  {'C': 0.03125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9049726333170256
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[251  54]
 [  9 325]]
Accuracy (<> F measure = f1score) is :  0.9014084507042254
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.82      0.89       305
           1       0.86      0.97      0.91       334

    accuracy                           0.90       639
   macro avg       0.91      0.90      0.90       639
weighted avg       0.91      0.90      0.90       639

F measure at 0 is :  0.8884955752212388
F measure at 1 is :  0.9116409537166901
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:18:42.870090
end clf.fit at :2019-12-09 06:19:00.935017
clf.best_params:  {'C': 0.03125, 'gamma': 0.5, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9034078400195694
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[255  50]
 [  9 325]]
Accuracy (<> F measure = f1score) is :  0.9076682316118936
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.84      0.90       305
           1       0.87      0.97      0.92       334

    accuracy                           0.91       639
   macro avg       0.92      0.90      0.91       639
weighted avg       0.91      0.91      0.91       639

F measure at 0 is :  0.8963093145869947
F measure at 1 is :  0.9167842031029619
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:19:00.950637
end clf.fit at :2019-12-09 06:19:19.027879
clf.best_params:  {'C': 0.03125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9045843016144814
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[251  54]
 [  8 326]]
Accuracy (<> F measure = f1score) is :  0.9029733959311425
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.82      0.89       305
           1       0.86      0.98      0.91       334

    accuracy                           0.90       639
   macro avg       0.91      0.90      0.90       639
weighted avg       0.91      0.90      0.90       639

F measure at 0 is :  0.8900709219858155
F measure at 1 is :  0.9131652661064426
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:19:19.064857
end clf.fit at :2019-12-09 06:19:37.230630
clf.best_params:  {'C': 0.03125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9022397871819962
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[254  52]
 [  4 329]]
Accuracy (<> F measure = f1score) is :  0.9123630672926447
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.98      0.83      0.90       306
           1       0.86      0.99      0.92       333

    accuracy                           0.91       639
   macro avg       0.92      0.91      0.91       639
weighted avg       0.92      0.91      0.91       639

F measure at 0 is :  0.900709219858156
F measure at 1 is :  0.9215686274509803
------------ end testing the model ------------
overall_accuracy:  0.9042553191489362
overall_f_measure:  0.9138513513513513
start clf.fit at :2019-12-09 06:19:37.275770
end clf.fit at :2019-12-09 06:19:37.275770
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6600866866438355
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 118]]
Accuracy (<> F measure = f1score) is :  0.6625
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       334

    accuracy                           0.66       640
   macro avg       0.79      0.68      0.63       640
weighted avg       0.80      0.66      0.63       640

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.5221238938053098
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:19:37.291392
end clf.fit at :2019-12-09 06:19:37.291392
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6649874633072408
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [228 106]]
Accuracy (<> F measure = f1score) is :  0.6431924882629108
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.57      1.00      0.73       305
           1       1.00      0.32      0.48       334

    accuracy                           0.64       639
   macro avg       0.79      0.66      0.60       639
weighted avg       0.80      0.64      0.60       639

F measure at 0 is :  0.7279236276849643
F measure at 1 is :  0.48181818181818187
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:19:37.310464
end clf.fit at :2019-12-09 06:19:37.317518
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6559855063600782
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [205 129]]
Accuracy (<> F measure = f1score) is :  0.6791862284820032
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.60      1.00      0.75       305
           1       1.00      0.39      0.56       334

    accuracy                           0.68       639
   macro avg       0.80      0.69      0.65       639
weighted avg       0.81      0.68      0.65       639

F measure at 0 is :  0.7484662576687116
F measure at 1 is :  0.5572354211663068
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:19:37.322452
end clf.fit at :2019-12-09 06:19:37.322452
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.661856347847358
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [220 114]]
Accuracy (<> F measure = f1score) is :  0.6557120500782473
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.58      1.00      0.73       305
           1       1.00      0.34      0.51       334

    accuracy                           0.66       639
   macro avg       0.79      0.67      0.62       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7349397590361446
F measure at 1 is :  0.5089285714285715
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:19:37.338003
end clf.fit at :2019-12-09 06:19:37.338003
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6602915545499022
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 117]]
Accuracy (<> F measure = f1score) is :  0.6619718309859155
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       333

    accuracy                           0.66       639
   macro avg       0.79      0.68      0.63       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.52
------------ end testing the model ------------
overall_accuracy:  0.6605131414267835
overall_f_measure:  0.5184198845983133
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  kr-vs-kp.arff-relevance-0.7-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (3196, 5)
dataset.head(5):              0             1             2             3  4
0  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
1  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
2  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
3  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
4  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
X_binary.shape:  (3196, 8)
start clf.fit at :2019-12-09 06:19:37.453648
end clf.fit at :2019-12-09 06:19:54.488949
clf.best_params:  {'C': 0.125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.945653436888454
clf.best_estimator_:  SVC(C=0.125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[275  31]
 [ 19 315]]
Accuracy (<> F measure = f1score) is :  0.921875
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.94      0.90      0.92       306
           1       0.91      0.94      0.93       334

    accuracy                           0.92       640
   macro avg       0.92      0.92      0.92       640
weighted avg       0.92      0.92      0.92       640

F measure at 0 is :  0.9166666666666667
F measure at 1 is :  0.9264705882352942
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:19:54.518245
end clf.fit at :2019-12-09 06:20:11.751232
clf.best_params:  {'C': 0.03125, 'gamma': 2, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9397948263209394
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf', max_iter=-1,
    probability=False, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[279  26]
 [  9 325]]
Accuracy (<> F measure = f1score) is :  0.945226917057903
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.91      0.94       305
           1       0.93      0.97      0.95       334

    accuracy                           0.95       639
   macro avg       0.95      0.94      0.94       639
weighted avg       0.95      0.95      0.95       639

F measure at 0 is :  0.9409780775716694
F measure at 1 is :  0.9489051094890512
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:20:11.766854
end clf.fit at :2019-12-09 06:20:28.802593
clf.best_params:  {'C': 0.03125, 'gamma': 2, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9413619129158514
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf', max_iter=-1,
    probability=False, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[275  30]
 [  9 325]]
Accuracy (<> F measure = f1score) is :  0.9389671361502347
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.90      0.93       305
           1       0.92      0.97      0.94       334

    accuracy                           0.94       639
   macro avg       0.94      0.94      0.94       639
weighted avg       0.94      0.94      0.94       639

F measure at 0 is :  0.933786078098472
F measure at 1 is :  0.9433962264150942
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:20:28.818216
end clf.fit at :2019-12-09 06:20:45.927460
clf.best_params:  {'C': 0.03125, 'gamma': 2, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9405829562133073
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf', max_iter=-1,
    probability=False, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[276  29]
 [  8 326]]
Accuracy (<> F measure = f1score) is :  0.9420970266040689
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.90      0.94       305
           1       0.92      0.98      0.95       334

    accuracy                           0.94       639
   macro avg       0.95      0.94      0.94       639
weighted avg       0.94      0.94      0.94       639

F measure at 0 is :  0.937181663837012
F measure at 1 is :  0.9462989840348331
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:20:45.949465
end clf.fit at :2019-12-09 06:21:03.412353
clf.best_params:  {'C': 0.03125, 'gamma': 2, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9370650379158512
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf', max_iter=-1,
    probability=False, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[282  24]
 [  4 329]]
Accuracy (<> F measure = f1score) is :  0.9561815336463224
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.99      0.92      0.95       306
           1       0.93      0.99      0.96       333

    accuracy                           0.96       639
   macro avg       0.96      0.95      0.96       639
weighted avg       0.96      0.96      0.96       639

F measure at 0 is :  0.9527027027027026
F measure at 1 is :  0.9591836734693878
------------ end testing the model ------------
overall_accuracy:  0.940863579474343
overall_f_measure:  0.9448818897637795
start clf.fit at :2019-12-09 06:21:03.440805
end clf.fit at :2019-12-09 06:21:03.440805
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6600866866438355
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 118]]
Accuracy (<> F measure = f1score) is :  0.6625
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       334

    accuracy                           0.66       640
   macro avg       0.79      0.68      0.63       640
weighted avg       0.80      0.66      0.63       640

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.5221238938053098
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:21:03.456414
end clf.fit at :2019-12-09 06:21:03.456414
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6649874633072408
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [228 106]]
Accuracy (<> F measure = f1score) is :  0.6431924882629108
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.57      1.00      0.73       305
           1       1.00      0.32      0.48       334

    accuracy                           0.64       639
   macro avg       0.79      0.66      0.60       639
weighted avg       0.80      0.64      0.60       639

F measure at 0 is :  0.7279236276849643
F measure at 1 is :  0.48181818181818187
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:21:03.472605
end clf.fit at :2019-12-09 06:21:03.472605
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6559855063600782
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [205 129]]
Accuracy (<> F measure = f1score) is :  0.6791862284820032
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.60      1.00      0.75       305
           1       1.00      0.39      0.56       334

    accuracy                           0.68       639
   macro avg       0.80      0.69      0.65       639
weighted avg       0.81      0.68      0.65       639

F measure at 0 is :  0.7484662576687116
F measure at 1 is :  0.5572354211663068
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:21:03.503897
end clf.fit at :2019-12-09 06:21:03.503897
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.661856347847358
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [220 114]]
Accuracy (<> F measure = f1score) is :  0.6557120500782473
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.58      1.00      0.73       305
           1       1.00      0.34      0.51       334

    accuracy                           0.66       639
   macro avg       0.79      0.67      0.62       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7349397590361446
F measure at 1 is :  0.5089285714285715
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:21:03.503897
end clf.fit at :2019-12-09 06:21:03.519486
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6602915545499022
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 117]]
Accuracy (<> F measure = f1score) is :  0.6619718309859155
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       333

    accuracy                           0.66       639
   macro avg       0.79      0.68      0.63       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.52
------------ end testing the model ------------
overall_accuracy:  0.6605131414267835
overall_f_measure:  0.5184198845983133
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  kr-vs-kp.arff-relevance-0.8-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (3196, 8)
dataset.head(5):             0             1            2             3             4             5             6  7
0  '(0.9-inf)'  '(-inf-0.1]'  '(0.9-inf)'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
1  '(0.9-inf)'  '(-inf-0.1]'  '(0.9-inf)'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
2  '(0.9-inf)'  '(-inf-0.1]'  '(0.9-inf)'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
3  '(0.9-inf)'  '(-inf-0.1]'  '(0.9-inf)'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
4  '(0.9-inf)'  '(-inf-0.1]'  '(0.9-inf)'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
X_binary.shape:  (3196, 15)
start clf.fit at :2019-12-09 06:21:03.657965
end clf.fit at :2019-12-09 06:21:34.424356
clf.best_params:  {'C': 0.5, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.945653436888454
clf.best_estimator_:  SVC(C=0.5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[275  31]
 [ 19 315]]
Accuracy (<> F measure = f1score) is :  0.921875
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.94      0.90      0.92       306
           1       0.91      0.94      0.93       334

    accuracy                           0.92       640
   macro avg       0.92      0.92      0.92       640
weighted avg       0.92      0.92      0.92       640

F measure at 0 is :  0.9166666666666667
F measure at 1 is :  0.9264705882352942
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:21:34.439973
end clf.fit at :2019-12-09 06:22:05.204067
clf.best_params:  {'C': 0.125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9394034368884541
clf.best_estimator_:  SVC(C=0.125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[279  26]
 [  9 325]]
Accuracy (<> F measure = f1score) is :  0.945226917057903
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.91      0.94       305
           1       0.93      0.97      0.95       334

    accuracy                           0.95       639
   macro avg       0.95      0.94      0.94       639
weighted avg       0.95      0.95      0.95       639

F measure at 0 is :  0.9409780775716694
F measure at 1 is :  0.9489051094890512
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:22:05.219721
end clf.fit at :2019-12-09 06:22:37.218860
clf.best_params:  {'C': 0.125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.93979635518591
clf.best_estimator_:  SVC(C=0.125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[275  30]
 [  9 325]]
Accuracy (<> F measure = f1score) is :  0.9389671361502347
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.90      0.93       305
           1       0.92      0.97      0.94       334

    accuracy                           0.94       639
   macro avg       0.94      0.94      0.94       639
weighted avg       0.94      0.94      0.94       639

F measure at 0 is :  0.933786078098472
F measure at 1 is :  0.9433962264150942
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:22:37.245903
end clf.fit at :2019-12-09 06:23:08.067752
clf.best_params:  {'C': 2, 'gamma': 0.5, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9409674657534246
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[280  25]
 [ 16 318]]
Accuracy (<> F measure = f1score) is :  0.9358372456964006
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.95      0.92      0.93       305
           1       0.93      0.95      0.94       334

    accuracy                           0.94       639
   macro avg       0.94      0.94      0.94       639
weighted avg       0.94      0.94      0.94       639

F measure at 0 is :  0.9317803660565724
F measure at 1 is :  0.9394387001477105
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:23:08.094575
end clf.fit at :2019-12-09 06:23:38.209388
clf.best_params:  {'C': 512, 'gamma': 0.001953125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9370650379158512
clf.best_estimator_:  SVC(C=512, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.001953125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[282  24]
 [  4 329]]
Accuracy (<> F measure = f1score) is :  0.9561815336463224
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.99      0.92      0.95       306
           1       0.93      0.99      0.96       333

    accuracy                           0.96       639
   macro avg       0.96      0.95      0.96       639
weighted avg       0.96      0.96      0.96       639

F measure at 0 is :  0.9527027027027026
F measure at 1 is :  0.9591836734693878
------------ end testing the model ------------
overall_accuracy:  0.9396120150187734
overall_f_measure:  0.9435177055896986
start clf.fit at :2019-12-09 06:23:38.238645
end clf.fit at :2019-12-09 06:23:38.238645
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6600866866438355
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 118]]
Accuracy (<> F measure = f1score) is :  0.6625
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       334

    accuracy                           0.66       640
   macro avg       0.79      0.68      0.63       640
weighted avg       0.80      0.66      0.63       640

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.5221238938053098
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:23:38.255802
end clf.fit at :2019-12-09 06:23:38.255802
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6649874633072408
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [228 106]]
Accuracy (<> F measure = f1score) is :  0.6431924882629108
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.57      1.00      0.73       305
           1       1.00      0.32      0.48       334

    accuracy                           0.64       639
   macro avg       0.79      0.66      0.60       639
weighted avg       0.80      0.64      0.60       639

F measure at 0 is :  0.7279236276849643
F measure at 1 is :  0.48181818181818187
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:23:38.273021
end clf.fit at :2019-12-09 06:23:38.273021
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6559855063600782
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [205 129]]
Accuracy (<> F measure = f1score) is :  0.6791862284820032
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.60      1.00      0.75       305
           1       1.00      0.39      0.56       334

    accuracy                           0.68       639
   macro avg       0.80      0.69      0.65       639
weighted avg       0.81      0.68      0.65       639

F measure at 0 is :  0.7484662576687116
F measure at 1 is :  0.5572354211663068
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:23:38.288675
end clf.fit at :2019-12-09 06:23:38.288675
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.661856347847358
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [220 114]]
Accuracy (<> F measure = f1score) is :  0.6557120500782473
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.58      1.00      0.73       305
           1       1.00      0.34      0.51       334

    accuracy                           0.66       639
   macro avg       0.79      0.67      0.62       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7349397590361446
F measure at 1 is :  0.5089285714285715
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:23:38.304296
end clf.fit at :2019-12-09 06:23:38.304296
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6602915545499022
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 117]]
Accuracy (<> F measure = f1score) is :  0.6619718309859155
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       333

    accuracy                           0.66       639
   macro avg       0.79      0.68      0.63       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.52
------------ end testing the model ------------
overall_accuracy:  0.6605131414267835
overall_f_measure:  0.5184198845983133
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  kr-vs-kp.arff-relevance-0.9-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (3196, 14)
dataset.head(5):             0             1             2             3            4             5   ...            8             9             10            11            12 13
0  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(0.9-inf)'  '(-inf-0.1]'  ...  '(-inf-0.1]'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
1  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(0.9-inf)'  '(-inf-0.1]'  ...  '(-inf-0.1]'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
2  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'   '(0.9-inf)'  '(0.9-inf)'  '(-inf-0.1]'  ...  '(-inf-0.1]'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
3   '(0.9-inf)'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(0.9-inf)'  '(-inf-0.1]'  ...  '(-inf-0.1]'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
4  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(0.9-inf)'  '(-inf-0.1]'  ...  '(-inf-0.1]'  '(-inf-0.3]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1

[5 rows x 14 columns]
X_binary.shape:  (3196, 27)
start clf.fit at :2019-12-09 06:23:38.544208
end clf.fit at :2019-12-09 06:24:24.265871
clf.best_params:  {'C': 2048, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9530722541585128
clf.best_estimator_:  SVC(C=2048, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[298   8]
 [ 18 316]]
Accuracy (<> F measure = f1score) is :  0.959375
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.94      0.97      0.96       306
           1       0.98      0.95      0.96       334

    accuracy                           0.96       640
   macro avg       0.96      0.96      0.96       640
weighted avg       0.96      0.96      0.96       640

F measure at 0 is :  0.9581993569131834
F measure at 1 is :  0.9604863221884499
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:24:24.284318
end clf.fit at :2019-12-09 06:25:10.458758
clf.best_params:  {'C': 2048, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9522887108610568
clf.best_estimator_:  SVC(C=2048, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[290  15]
 [ 10 324]]
Accuracy (<> F measure = f1score) is :  0.9608763693270735
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.95      0.96       305
           1       0.96      0.97      0.96       334

    accuracy                           0.96       639
   macro avg       0.96      0.96      0.96       639
weighted avg       0.96      0.96      0.96       639

F measure at 0 is :  0.9586776859504132
F measure at 1 is :  0.962852897473997
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:25:10.476091
end clf.fit at :2019-12-09 06:25:57.019602
clf.best_params:  {'C': 2048, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9534705234833659
clf.best_estimator_:  SVC(C=2048, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[296   9]
 [  8 326]]
Accuracy (<> F measure = f1score) is :  0.97339593114241
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.97      0.97       305
           1       0.97      0.98      0.97       334

    accuracy                           0.97       639
   macro avg       0.97      0.97      0.97       639
weighted avg       0.97      0.97      0.97       639

F measure at 0 is :  0.9720853858784894
F measure at 1 is :  0.9745889387144994
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:25:57.049055
end clf.fit at :2019-12-09 06:26:42.297565
clf.best_params:  {'C': 8192, 'gamma': 0.001953125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9562048984833659
clf.best_estimator_:  SVC(C=8192, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.001953125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[297   8]
 [ 11 323]]
Accuracy (<> F measure = f1score) is :  0.9702660406885759
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.96      0.97      0.97       305
           1       0.98      0.97      0.97       334

    accuracy                           0.97       639
   macro avg       0.97      0.97      0.97       639
weighted avg       0.97      0.97      0.97       639

F measure at 0 is :  0.9690048939641109
F measure at 1 is :  0.9714285714285713
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:26:42.313200
end clf.fit at :2019-12-09 06:27:29.251356
clf.best_params:  {'C': 32, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9421271098336594
clf.best_estimator_:  SVC(C=32, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[301   5]
 [ 10 323]]
Accuracy (<> F measure = f1score) is :  0.9765258215962441
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.97      0.98      0.98       306
           1       0.98      0.97      0.98       333

    accuracy                           0.98       639
   macro avg       0.98      0.98      0.98       639
weighted avg       0.98      0.98      0.98       639

F measure at 0 is :  0.9756888168557536
F measure at 1 is :  0.9773071104387292
------------ end testing the model ------------
overall_accuracy:  0.9680851063829787
overall_f_measure:  0.9693325315694528
start clf.fit at :2019-12-09 06:27:29.283717
end clf.fit at :2019-12-09 06:27:29.283717
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6620436338062622
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 118]]
Accuracy (<> F measure = f1score) is :  0.6625
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       334

    accuracy                           0.66       640
   macro avg       0.79      0.68      0.63       640
weighted avg       0.80      0.66      0.63       640

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.5221238938053098
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:27:29.299342
end clf.fit at :2019-12-09 06:27:29.314959
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6700755259295499
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [227 107]]
Accuracy (<> F measure = f1score) is :  0.6447574334898278
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.57      1.00      0.73       305
           1       1.00      0.32      0.49       334

    accuracy                           0.64       639
   macro avg       0.79      0.66      0.61       639
weighted avg       0.80      0.64      0.60       639

F measure at 0 is :  0.7287933094384708
F measure at 1 is :  0.48526077097505665
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:27:29.330563
end clf.fit at :2019-12-09 06:27:29.330563
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6579424535225049
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [204 130]]
Accuracy (<> F measure = f1score) is :  0.6807511737089202
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.60      1.00      0.75       305
           1       1.00      0.39      0.56       334

    accuracy                           0.68       639
   macro avg       0.80      0.69      0.65       639
weighted avg       0.81      0.68      0.65       639

F measure at 0 is :  0.7493857493857494
F measure at 1 is :  0.5603448275862069
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:27:29.346184
end clf.fit at :2019-12-09 06:27:29.346184
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6622477372798434
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   0]
 [218 116]]
Accuracy (<> F measure = f1score) is :  0.6588419405320813
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.58      1.00      0.74       305
           1       1.00      0.35      0.52       334

    accuracy                           0.66       639
   macro avg       0.79      0.67      0.63       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7367149758454106
F measure at 1 is :  0.5155555555555555
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:27:29.361805
end clf.fit at :2019-12-09 06:27:29.377433
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6653796171722114
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[306   0]
 [216 117]]
Accuracy (<> F measure = f1score) is :  0.6619718309859155
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      1.00      0.74       306
           1       1.00      0.35      0.52       333

    accuracy                           0.66       639
   macro avg       0.79      0.68      0.63       639
weighted avg       0.80      0.66      0.62       639

F measure at 0 is :  0.7391304347826086
F measure at 1 is :  0.52
------------ end testing the model ------------
overall_accuracy:  0.6617647058823529
overall_f_measure:  0.5210456357997342
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  kr-vs-kp.arff-relevance-1.0-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (3196, 37)
dataset.head(5):             0             1             2             3             4            5   ...           31           32            33            34            35 36
0  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(0.9-inf)'  ...  '(0.9-inf)'  '(0.9-inf)'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
1  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(0.9-inf)'  ...  '(0.9-inf)'  '(0.9-inf)'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
2  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(0.9-inf)'  ...  '(0.9-inf)'  '(0.9-inf)'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
3  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(0.9-inf)'  ...  '(0.9-inf)'  '(0.9-inf)'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1
4  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  '(0.9-inf)'  ...  '(0.9-inf)'  '(0.9-inf)'  '(-inf-0.1]'  '(-inf-0.1]'  '(-inf-0.1]'  1

[5 rows x 37 columns]
X_binary.shape:  (3196, 73)
start clf.fit at :2019-12-09 06:27:29.940313
end clf.fit at :2019-12-09 06:29:49.657126
clf.best_params:  {'C': 32, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9714507399706458
clf.best_estimator_:  SVC(C=32, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[303   3]
 [  4 330]]
Accuracy (<> F measure = f1score) is :  0.9890625
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.99      0.99      0.99       306
           1       0.99      0.99      0.99       334

    accuracy                           0.99       640
   macro avg       0.99      0.99      0.99       640
weighted avg       0.99      0.99      0.99       640

F measure at 0 is :  0.9885807504078303
F measure at 1 is :  0.9895052473763118
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:29:49.698108
end clf.fit at :2019-12-09 06:32:08.597737
clf.best_params:  {'C': 128, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9722342832681019
clf.best_estimator_:  SVC(C=128, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[301   4]
 [  5 329]]
Accuracy (<> F measure = f1score) is :  0.9859154929577465
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.98      0.99      0.99       305
           1       0.99      0.99      0.99       334

    accuracy                           0.99       639
   macro avg       0.99      0.99      0.99       639
weighted avg       0.99      0.99      0.99       639

F measure at 0 is :  0.9852700490998363
F measure at 1 is :  0.9865067466266867
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:32:08.622564
end clf.fit at :2019-12-09 06:34:28.089366
clf.best_params:  {'C': 512, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.971060879403131
clf.best_estimator_:  SVC(C=512, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[301   4]
 [  0 334]]
Accuracy (<> F measure = f1score) is :  0.9937402190923318
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       1.00      0.99      0.99       305
           1       0.99      1.00      0.99       334

    accuracy                           0.99       639
   macro avg       0.99      0.99      0.99       639
weighted avg       0.99      0.99      0.99       639

F measure at 0 is :  0.9933993399339933
F measure at 1 is :  0.9940476190476192
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:34:28.121209
end clf.fit at :2019-12-09 06:36:47.648771
clf.best_params:  {'C': 512, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9753608121330724
clf.best_estimator_:  SVC(C=512, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[301   4]
 [  3 331]]
Accuracy (<> F measure = f1score) is :  0.9890453834115805
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.99      0.99      0.99       305
           1       0.99      0.99      0.99       334

    accuracy                           0.99       639
   macro avg       0.99      0.99      0.99       639
weighted avg       0.99      0.99      0.99       639

F measure at 0 is :  0.9885057471264368
F measure at 1 is :  0.9895366218236173
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:36:47.680017
end clf.fit at :2019-12-09 06:39:07.751903
clf.best_params:  {'C': 512, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.9659712879158512
clf.best_estimator_:  SVC(C=512, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[305   1]
 [  1 332]]
Accuracy (<> F measure = f1score) is :  0.9968701095461658
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       1.00      1.00      1.00       306
           1       1.00      1.00      1.00       333

    accuracy                           1.00       639
   macro avg       1.00      1.00      1.00       639
weighted avg       1.00      1.00      1.00       639

F measure at 0 is :  0.9967320261437909
F measure at 1 is :  0.996996996996997
------------ end testing the model ------------
overall_accuracy:  0.9909261576971214
overall_f_measure:  0.99131996408261
start clf.fit at :2019-12-09 06:39:07.783146
end clf.fit at :2019-12-09 06:39:07.814388
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6404843444227005
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 86 220]
 [ 11 323]]
Accuracy (<> F measure = f1score) is :  0.6390625
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.89      0.28      0.43       306
           1       0.59      0.97      0.74       334

    accuracy                           0.64       640
   macro avg       0.74      0.62      0.58       640
weighted avg       0.73      0.64      0.59       640

F measure at 0 is :  0.4267990074441688
F measure at 1 is :  0.7366020524515394
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:39:07.814388
end clf.fit at :2019-12-09 06:39:07.845639
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6254074425146771
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 47 258]
 [  2 332]]
Accuracy (<> F measure = f1score) is :  0.593114241001565
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.96      0.15      0.27       305
           1       0.56      0.99      0.72       334

    accuracy                           0.59       639
   macro avg       0.76      0.57      0.49       639
weighted avg       0.75      0.59      0.50       639

F measure at 0 is :  0.26553672316384175
F measure at 1 is :  0.7186147186147186
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:39:07.845639
end clf.fit at :2019-12-09 06:39:07.876874
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.627365154109589
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 62 243]
 [  0 334]]
Accuracy (<> F measure = f1score) is :  0.6197183098591549
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       1.00      0.20      0.34       305
           1       0.58      1.00      0.73       334

    accuracy                           0.62       639
   macro avg       0.79      0.60      0.54       639
weighted avg       0.78      0.62      0.54       639

F measure at 0 is :  0.33787465940054495
F measure at 1 is :  0.7332601536772777
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:39:07.876874
end clf.fit at :2019-12-09 06:39:07.908123
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6183639615949119
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 67 238]
 [  0 334]]
Accuracy (<> F measure = f1score) is :  0.6275430359937402
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       1.00      0.22      0.36       305
           1       0.58      1.00      0.74       334

    accuracy                           0.63       639
   macro avg       0.79      0.61      0.55       639
weighted avg       0.78      0.63      0.56       639

F measure at 0 is :  0.3602150537634409
F measure at 1 is :  0.7373068432671082
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:39:07.913359
end clf.fit at :2019-12-09 06:39:07.929058
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6269707069471624
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 70 236]
 [  0 333]]
Accuracy (<> F measure = f1score) is :  0.6306729264475743
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       1.00      0.23      0.37       306
           1       0.59      1.00      0.74       333

    accuracy                           0.63       639
   macro avg       0.79      0.61      0.56       639
weighted avg       0.78      0.63      0.56       639

F measure at 0 is :  0.3723404255319149
F measure at 1 is :  0.738359201773836
------------ end testing the model ------------
overall_accuracy:  0.6220275344180225
overall_f_measure:  0.7327433628318584
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-noise-0.5-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 6)
dataset.head(5):                 0                1                2              3                4  5
0  '(477.5-500.6]'  '(433.4-464.1]'  '(539.3-556.2]'  '(476.4-491]'  '(474.7-475.6]'  0
1  '(477.5-500.6]'  '(525.5-556.2]'  '(488.6-505.5]'  '(476.4-491]'  '(474.7-475.6]'  0
2  '(454.4-477.5]'  '(464.1-494.8]'  '(505.5-522.4]'  '(476.4-491]'  '(474.7-475.6]'  0
3  '(477.5-500.6]'  '(494.8-525.5]'  '(488.6-505.5]'  '(491-505.6]'  '(475.6-476.5]'  1
4  '(523.7-546.8]'  '(494.8-525.5]'  '(471.7-488.6]'  '(476.4-491]'  '(475.6-476.5]'  1
X_binary.shape:  (2000, 50)
start clf.fit at :2019-12-09 06:39:08.045933
end clf.fit at :2019-12-09 06:41:43.627499
clf.best_params:  {'C': 8, 'gamma': 0.5, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.5131249999999999
clf.best_estimator_:  SVC(C=8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[101  99]
 [ 98 102]]
Accuracy (<> F measure = f1score) is :  0.5075
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.51      0.51       200
           1       0.51      0.51      0.51       200

    accuracy                           0.51       400
   macro avg       0.51      0.51      0.51       400
weighted avg       0.51      0.51      0.51       400

F measure at 0 is :  0.5062656641604011
F measure at 1 is :  0.5087281795511223
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:41:43.705607
end clf.fit at :2019-12-09 06:44:21.475131
clf.best_params:  {'C': 8192, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.526875
clf.best_estimator_:  SVC(C=8192, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 91 109]
 [106  94]]
Accuracy (<> F measure = f1score) is :  0.4625
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.46      0.46      0.46       200
           1       0.46      0.47      0.47       200

    accuracy                           0.46       400
   macro avg       0.46      0.46      0.46       400
weighted avg       0.46      0.46      0.46       400

F measure at 0 is :  0.45843828715365237
F measure at 1 is :  0.46650124069478904
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:44:21.538001
end clf.fit at :2019-12-09 06:46:49.602334
clf.best_params:  {'C': 2, 'gamma': 2, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.539375
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf', max_iter=-1,
    probability=False, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[115  85]
 [126  74]]
Accuracy (<> F measure = f1score) is :  0.4725
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.48      0.57      0.52       200
           1       0.47      0.37      0.41       200

    accuracy                           0.47       400
   macro avg       0.47      0.47      0.47       400
weighted avg       0.47      0.47      0.47       400

F measure at 0 is :  0.5215419501133786
F measure at 1 is :  0.4122562674094708
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:46:49.666386
end clf.fit at :2019-12-09 06:49:32.458004
clf.best_params:  {'C': 32768, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.5162500000000001
clf.best_estimator_:  SVC(C=32768, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 97 103]
 [101  99]]
Accuracy (<> F measure = f1score) is :  0.49
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.49      0.48      0.49       200
           1       0.49      0.49      0.49       200

    accuracy                           0.49       400
   macro avg       0.49      0.49      0.49       400
weighted avg       0.49      0.49      0.49       400

F measure at 0 is :  0.4874371859296482
F measure at 1 is :  0.4925373134328358
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:49:32.520486
end clf.fit at :2019-12-09 06:52:04.581088
clf.best_params:  {'C': 2048, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.519375
clf.best_estimator_:  SVC(C=2048, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[107  93]
 [ 94 106]]
Accuracy (<> F measure = f1score) is :  0.5325
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.53      0.54      0.53       200
           1       0.53      0.53      0.53       200

    accuracy                           0.53       400
   macro avg       0.53      0.53      0.53       400
weighted avg       0.53      0.53      0.53       400

F measure at 0 is :  0.5336658354114714
F measure at 1 is :  0.531328320802005
------------ end testing the model ------------
overall_accuracy:  0.493
overall_f_measure:  0.48370672097759676
start clf.fit at :2019-12-09 06:52:04.636559
end clf.fit at :2019-12-09 06:52:04.652179
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.49499999999999994
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[  9 191]
 [ 11 189]]
Accuracy (<> F measure = f1score) is :  0.495
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.45      0.04      0.08       200
           1       0.50      0.94      0.65       200

    accuracy                           0.49       400
   macro avg       0.47      0.49      0.37       400
weighted avg       0.47      0.49      0.37       400

F measure at 0 is :  0.08181818181818182
F measure at 1 is :  0.6517241379310345
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:52:04.652179
end clf.fit at :2019-12-09 06:52:04.667800
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.4956250000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 12 188]
 [  6 194]]
Accuracy (<> F measure = f1score) is :  0.515
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.67      0.06      0.11       200
           1       0.51      0.97      0.67       200

    accuracy                           0.52       400
   macro avg       0.59      0.52      0.39       400
weighted avg       0.59      0.52      0.39       400

F measure at 0 is :  0.11009174311926605
F measure at 1 is :  0.6666666666666667
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:52:04.667800
end clf.fit at :2019-12-09 06:52:04.683602
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.500625
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[  4 196]
 [  5 195]]
Accuracy (<> F measure = f1score) is :  0.4975
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.44      0.02      0.04       200
           1       0.50      0.97      0.66       200

    accuracy                           0.50       400
   macro avg       0.47      0.50      0.35       400
weighted avg       0.47      0.50      0.35       400

F measure at 0 is :  0.03827751196172249
F measure at 1 is :  0.6598984771573604
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:52:04.699515
end clf.fit at :2019-12-09 06:52:04.706997
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.50125
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[  1 199]
 [  4 196]]
Accuracy (<> F measure = f1score) is :  0.4925
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.20      0.01      0.01       200
           1       0.50      0.98      0.66       200

    accuracy                           0.49       400
   macro avg       0.35      0.49      0.33       400
weighted avg       0.35      0.49      0.33       400

F measure at 0 is :  0.00975609756097561
F measure at 1 is :  0.6588235294117647
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:52:04.706997
end clf.fit at :2019-12-09 06:52:04.722649
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.499375
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[  7 193]
 [  7 193]]
Accuracy (<> F measure = f1score) is :  0.5
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.04      0.07       200
           1       0.50      0.96      0.66       200

    accuracy                           0.50       400
   macro avg       0.50      0.50      0.36       400
weighted avg       0.50      0.50      0.36       400

F measure at 0 is :  0.06542056074766356
F measure at 1 is :  0.658703071672355
------------ end testing the model ------------
overall_accuracy:  0.5
overall_f_measure:  0.6591683708248125
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-noise-0.6-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 6)
dataset.head(5):                 0                1                2              3            4  5
0  '(511.5-537.4]'  '(536.4-564.3]'  '(476.6-499.5]'  '(476.8-490]'  '(479-482]'  0
1  '(511.5-537.4]'  '(424.8-452.7]'  '(453.7-476.6]'  '(490-503.2]'  '(479-482]'  0
2  '(537.4-563.3]'  '(508.5-536.4]'  '(499.5-522.4]'  '(476.8-490]'  '(470-473]'  0
3  '(407.9-433.8]'  '(452.7-480.6]'  '(499.5-522.4]'  '(490-503.2]'  '(479-482]'  1
4  '(511.5-537.4]'  '(536.4-564.3]'  '(476.6-499.5]'  '(476.8-490]'  '(479-482]'  1
X_binary.shape:  (2000, 50)
start clf.fit at :2019-12-09 06:52:04.814506
end clf.fit at :2019-12-09 06:54:31.336668
clf.best_params:  {'C': 512, 'gamma': 0.0001220703125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.5050000000000001
clf.best_estimator_:  SVC(C=512, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0001220703125,
    kernel='rbf', max_iter=-1, probability=False, random_state=None,
    shrinking=True, tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[121  79]
 [130  70]]
Accuracy (<> F measure = f1score) is :  0.4775
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.48      0.60      0.54       200
           1       0.47      0.35      0.40       200

    accuracy                           0.48       400
   macro avg       0.48      0.48      0.47       400
weighted avg       0.48      0.48      0.47       400

F measure at 0 is :  0.5365853658536586
F measure at 1 is :  0.40114613180515757
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:54:31.404325
end clf.fit at :2019-12-09 06:56:57.835253
clf.best_params:  {'C': 0.5, 'gamma': 8, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.49874999999999997
clf.best_estimator_:  SVC(C=0.5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=8, kernel='rbf', max_iter=-1,
    probability=False, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 22 178]
 [ 28 172]]
Accuracy (<> F measure = f1score) is :  0.485
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.44      0.11      0.18       200
           1       0.49      0.86      0.63       200

    accuracy                           0.48       400
   macro avg       0.47      0.48      0.40       400
weighted avg       0.47      0.48      0.40       400

F measure at 0 is :  0.176
F measure at 1 is :  0.6254545454545454
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:56:57.913383
end clf.fit at :2019-12-09 06:59:27.453251
clf.best_params:  {'C': 2, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.5043750000000001
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 98 102]
 [ 91 109]]
Accuracy (<> F measure = f1score) is :  0.5175
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.52      0.49      0.50       200
           1       0.52      0.55      0.53       200

    accuracy                           0.52       400
   macro avg       0.52      0.52      0.52       400
weighted avg       0.52      0.52      0.52       400

F measure at 0 is :  0.5038560411311055
F measure at 1 is :  0.5304136253041363
------------ end testing the model ------------
start clf.fit at :2019-12-09 06:59:27.529520
end clf.fit at :2019-12-09 07:01:48.327088
clf.best_params:  {'C': 0.03125, 'gamma': 0.5, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.50625
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 72 128]
 [ 83 117]]
Accuracy (<> F measure = f1score) is :  0.4725
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.46      0.36      0.41       200
           1       0.48      0.58      0.53       200

    accuracy                           0.47       400
   macro avg       0.47      0.47      0.47       400
weighted avg       0.47      0.47      0.47       400

F measure at 0 is :  0.4056338028169014
F measure at 1 is :  0.5258426966292136
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:01:48.389571
end clf.fit at :2019-12-09 07:04:11.634718
clf.best_params:  {'C': 2, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.5293749999999999
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 96 104]
 [115  85]]
Accuracy (<> F measure = f1score) is :  0.4525
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.45      0.48      0.47       200
           1       0.45      0.42      0.44       200

    accuracy                           0.45       400
   macro avg       0.45      0.45      0.45       400
weighted avg       0.45      0.45      0.45       400

F measure at 0 is :  0.4671532846715328
F measure at 1 is :  0.4370179948586118
------------ end testing the model ------------
overall_accuracy:  0.481
overall_f_measure:  0.5158582089552238
start clf.fit at :2019-12-09 07:04:11.720762
end clf.fit at :2019-12-09 07:04:11.720762
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.49375
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[152  48]
 [161  39]]
Accuracy (<> F measure = f1score) is :  0.4775
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.49      0.76      0.59       200
           1       0.45      0.20      0.27       200

    accuracy                           0.48       400
   macro avg       0.47      0.48      0.43       400
weighted avg       0.47      0.48      0.43       400

F measure at 0 is :  0.5925925925925927
F measure at 1 is :  0.27177700348432055
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:04:11.736441
end clf.fit at :2019-12-09 07:04:11.736441
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.49812500000000004
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[191   9]
 [192   8]]
Accuracy (<> F measure = f1score) is :  0.4975
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.95      0.66       200
           1       0.47      0.04      0.07       200

    accuracy                           0.50       400
   macro avg       0.48      0.50      0.36       400
weighted avg       0.48      0.50      0.36       400

F measure at 0 is :  0.6552315608919382
F measure at 1 is :  0.07373271889400922
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:04:11.752036
end clf.fit at :2019-12-09 07:04:11.752036
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.506875
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[186  14]
 [180  20]]
Accuracy (<> F measure = f1score) is :  0.515
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.93      0.66       200
           1       0.59      0.10      0.17       200

    accuracy                           0.52       400
   macro avg       0.55      0.52      0.41       400
weighted avg       0.55      0.52      0.41       400

F measure at 0 is :  0.657243816254417
F measure at 1 is :  0.17094017094017097
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:04:11.774553
end clf.fit at :2019-12-09 07:04:11.783843
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.48250000000000004
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 24 176]
 [ 18 182]]
Accuracy (<> F measure = f1score) is :  0.515
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.57      0.12      0.20       200
           1       0.51      0.91      0.65       200

    accuracy                           0.52       400
   macro avg       0.54      0.52      0.43       400
weighted avg       0.54      0.52      0.43       400

F measure at 0 is :  0.1983471074380165
F measure at 1 is :  0.6523297491039426
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:04:11.784778
end clf.fit at :2019-12-09 07:04:11.800466
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.51
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 10 190]
 [  9 191]]
Accuracy (<> F measure = f1score) is :  0.5025
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.53      0.05      0.09       200
           1       0.50      0.95      0.66       200

    accuracy                           0.50       400
   macro avg       0.51      0.50      0.37       400
weighted avg       0.51      0.50      0.37       400

F measure at 0 is :  0.091324200913242
F measure at 1 is :  0.6574870912220311
------------ end testing the model ------------
overall_accuracy:  0.5015
overall_f_measure:  0.46883324453915826
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-noise-0.7-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 6)
dataset.head(5):             0                1                2                3                4  5
0  '(429-461]'  '(428.9-456.2]'    '(479.8-506]'  '(517.8-534.1]'  '(479.6-486.5]'  0
1  '(525-557]'  '(456.2-483.5]'    '(506-532.2]'  '(501.5-517.8]'  '(486.5-493.4]'  0
2  '(461-493]'  '(510.8-538.1]'  '(453.6-479.8]'  '(485.2-501.5]'  '(472.7-479.6]'  0
3  '(557-589]'  '(456.2-483.5]'    '(506-532.2]'  '(452.6-468.9]'  '(493.4-500.3]'  1
4  '(525-557]'  '(510.8-538.1]'    '(506-532.2]'  '(452.6-468.9]'  '(472.7-479.6]'  1
X_binary.shape:  (2000, 50)
start clf.fit at :2019-12-09 07:04:11.891530
end clf.fit at :2019-12-09 07:06:33.665386
clf.best_params:  {'C': 0.125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.625
clf.best_estimator_:  SVC(C=0.125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[122  78]
 [ 91 109]]
Accuracy (<> F measure = f1score) is :  0.5775
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.57      0.61      0.59       200
           1       0.58      0.55      0.56       200

    accuracy                           0.58       400
   macro avg       0.58      0.58      0.58       400
weighted avg       0.58      0.58      0.58       400

F measure at 0 is :  0.5907990314769976
F measure at 1 is :  0.5633074935400517
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:06:33.733096
end clf.fit at :2019-12-09 07:08:53.985288
clf.best_params:  {'C': 128, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.6268749999999998
clf.best_estimator_:  SVC(C=128, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[103  97]
 [ 62 138]]
Accuracy (<> F measure = f1score) is :  0.6025
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.62      0.52      0.56       200
           1       0.59      0.69      0.63       200

    accuracy                           0.60       400
   macro avg       0.61      0.60      0.60       400
weighted avg       0.61      0.60      0.60       400

F measure at 0 is :  0.5643835616438356
F measure at 1 is :  0.6344827586206896
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:08:54.047779
end clf.fit at :2019-12-09 07:11:17.825648
clf.best_params:  {'C': 0.5, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.6175
clf.best_estimator_:  SVC(C=0.5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[120  80]
 [ 70 130]]
Accuracy (<> F measure = f1score) is :  0.625
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.63      0.60      0.62       200
           1       0.62      0.65      0.63       200

    accuracy                           0.62       400
   macro avg       0.63      0.62      0.62       400
weighted avg       0.63      0.62      0.62       400

F measure at 0 is :  0.6153846153846154
F measure at 1 is :  0.6341463414634146
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:11:17.891492
end clf.fit at :2019-12-09 07:13:43.527358
clf.best_params:  {'C': 0.5, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.615625
clf.best_estimator_:  SVC(C=0.5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[123  77]
 [ 69 131]]
Accuracy (<> F measure = f1score) is :  0.635
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.64      0.61      0.63       200
           1       0.63      0.66      0.64       200

    accuracy                           0.64       400
   macro avg       0.64      0.64      0.63       400
weighted avg       0.64      0.64      0.63       400

F measure at 0 is :  0.6275510204081632
F measure at 1 is :  0.642156862745098
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:13:43.595666
end clf.fit at :2019-12-09 07:16:10.778167
clf.best_params:  {'C': 128, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.625625
clf.best_estimator_:  SVC(C=128, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[111  89]
 [ 59 141]]
Accuracy (<> F measure = f1score) is :  0.63
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.65      0.56      0.60       200
           1       0.61      0.70      0.66       200

    accuracy                           0.63       400
   macro avg       0.63      0.63      0.63       400
weighted avg       0.63      0.63      0.63       400

F measure at 0 is :  0.6
F measure at 1 is :  0.6558139534883721
------------ end testing the model ------------
overall_accuracy:  0.614
overall_f_measure:  0.6270531400966184
start clf.fit at :2019-12-09 07:16:10.840605
end clf.fit at :2019-12-09 07:16:10.840605
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.510625
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[197   3]
 [196   4]]
Accuracy (<> F measure = f1score) is :  0.5025
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.98      0.66       200
           1       0.57      0.02      0.04       200

    accuracy                           0.50       400
   macro avg       0.54      0.50      0.35       400
weighted avg       0.54      0.50      0.35       400

F measure at 0 is :  0.6644182124789206
F measure at 1 is :  0.03864734299516908
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:16:10.871848
end clf.fit at :2019-12-09 07:16:10.871848
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.508125
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[191   9]
 [186  14]]
Accuracy (<> F measure = f1score) is :  0.5125
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.95      0.66       200
           1       0.61      0.07      0.13       200

    accuracy                           0.51       400
   macro avg       0.56      0.51      0.39       400
weighted avg       0.56      0.51      0.39       400

F measure at 0 is :  0.6620450606585788
F measure at 1 is :  0.12556053811659193
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:16:10.887469
end clf.fit at :2019-12-09 07:16:10.903092
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5293750000000002
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[186  14]
 [184  16]]
Accuracy (<> F measure = f1score) is :  0.505
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.93      0.65       200
           1       0.53      0.08      0.14       200

    accuracy                           0.51       400
   macro avg       0.52      0.51      0.40       400
weighted avg       0.52      0.51      0.40       400

F measure at 0 is :  0.6526315789473685
F measure at 1 is :  0.1391304347826087
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:16:10.918712
end clf.fit at :2019-12-09 07:16:10.918712
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5025000000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[195   5]
 [196   4]]
Accuracy (<> F measure = f1score) is :  0.4975
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.97      0.66       200
           1       0.44      0.02      0.04       200

    accuracy                           0.50       400
   macro avg       0.47      0.50      0.35       400
weighted avg       0.47      0.50      0.35       400

F measure at 0 is :  0.6598984771573604
F measure at 1 is :  0.03827751196172249
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:16:10.934333
end clf.fit at :2019-12-09 07:16:10.934333
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.4987500000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[198   2]
 [194   6]]
Accuracy (<> F measure = f1score) is :  0.51
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.99      0.67       200
           1       0.75      0.03      0.06       200

    accuracy                           0.51       400
   macro avg       0.63      0.51      0.36       400
weighted avg       0.63      0.51      0.36       400

F measure at 0 is :  0.6689189189189189
F measure at 1 is :  0.05769230769230769
------------ end testing the model ------------
overall_accuracy:  0.5055
overall_f_measure:  0.08170844939647168
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-noise-0.8-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 6)
dataset.head(5):                 0                1                2                3              4  5
0   '(99.9-199.8]'  '(509.5-535.6]'  '(454.2-478.6]'  '(505.5-526.6]'  '(476.4-491]'  0
1  '(399.6-499.5]'  '(483.4-509.5]'  '(527.4-551.8]'  '(505.5-526.6]'  '(476.4-491]'  0
2  '(499.5-599.4]'  '(483.4-509.5]'    '(503-527.4]'  '(484.4-505.5]'  '(476.4-491]'  0
3  '(599.4-699.3]'  '(457.3-483.4]'    '(503-527.4]'  '(526.6-547.7]'  '(491-505.6]'  1
4  '(399.6-499.5]'  '(509.5-535.6]'    '(478.6-503]'  '(421.1-442.2]'  '(476.4-491]'  1
X_binary.shape:  (2000, 50)
start clf.fit at :2019-12-09 07:16:11.038041
end clf.fit at :2019-12-09 07:18:37.004667
clf.best_params:  {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.5725
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[115  85]
 [ 95 105]]
Accuracy (<> F measure = f1score) is :  0.55
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.55      0.57      0.56       200
           1       0.55      0.53      0.54       200

    accuracy                           0.55       400
   macro avg       0.55      0.55      0.55       400
weighted avg       0.55      0.55      0.55       400

F measure at 0 is :  0.5609756097560975
F measure at 1 is :  0.5384615384615385
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:18:37.073987
end clf.fit at :2019-12-09 07:21:02.512808
clf.best_params:  {'C': 0.5, 'gamma': 0.5, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.563125
clf.best_estimator_:  SVC(C=0.5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 99 101]
 [ 72 128]]
Accuracy (<> F measure = f1score) is :  0.5675
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.58      0.49      0.53       200
           1       0.56      0.64      0.60       200

    accuracy                           0.57       400
   macro avg       0.57      0.57      0.57       400
weighted avg       0.57      0.57      0.57       400

F measure at 0 is :  0.5336927223719675
F measure at 1 is :  0.5967365967365966
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:21:02.583514
end clf.fit at :2019-12-09 07:23:27.664938
clf.best_params:  {'C': 8, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.57
clf.best_estimator_:  SVC(C=8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[106  94]
 [ 72 128]]
Accuracy (<> F measure = f1score) is :  0.585
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.60      0.53      0.56       200
           1       0.58      0.64      0.61       200

    accuracy                           0.58       400
   macro avg       0.59      0.58      0.58       400
weighted avg       0.59      0.58      0.58       400

F measure at 0 is :  0.5608465608465608
F measure at 1 is :  0.6066350710900474
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:23:27.730100
end clf.fit at :2019-12-09 07:25:50.802551
clf.best_params:  {'C': 32, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.575625
clf.best_estimator_:  SVC(C=32, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[104  96]
 [ 92 108]]
Accuracy (<> F measure = f1score) is :  0.53
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.53      0.52      0.53       200
           1       0.53      0.54      0.53       200

    accuracy                           0.53       400
   macro avg       0.53      0.53      0.53       400
weighted avg       0.53      0.53      0.53       400

F measure at 0 is :  0.5252525252525252
F measure at 1 is :  0.5346534653465347
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:25:50.865008
end clf.fit at :2019-12-09 07:28:08.985319
clf.best_params:  {'C': 2, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.593125
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[113  87]
 [ 97 103]]
Accuracy (<> F measure = f1score) is :  0.54
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.54      0.56      0.55       200
           1       0.54      0.52      0.53       200

    accuracy                           0.54       400
   macro avg       0.54      0.54      0.54       400
weighted avg       0.54      0.54      0.54       400

F measure at 0 is :  0.551219512195122
F measure at 1 is :  0.5282051282051282
------------ end testing the model ------------
overall_accuracy:  0.5545
overall_f_measure:  0.5621621621621622
start clf.fit at :2019-12-09 07:28:09.052888
end clf.fit at :2019-12-09 07:28:09.052888
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.521875
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[198   2]
 [188  12]]
Accuracy (<> F measure = f1score) is :  0.525
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.99      0.68       200
           1       0.86      0.06      0.11       200

    accuracy                           0.53       400
   macro avg       0.69      0.53      0.39       400
weighted avg       0.69      0.53      0.39       400

F measure at 0 is :  0.6757679180887373
F measure at 1 is :  0.11214953271028037
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:28:09.068499
end clf.fit at :2019-12-09 07:28:09.084130
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5506249999999999
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[188  12]
 [165  35]]
Accuracy (<> F measure = f1score) is :  0.5575
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.53      0.94      0.68       200
           1       0.74      0.17      0.28       200

    accuracy                           0.56       400
   macro avg       0.64      0.56      0.48       400
weighted avg       0.64      0.56      0.48       400

F measure at 0 is :  0.6799276672694393
F measure at 1 is :  0.2834008097165992
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:28:09.100213
end clf.fit at :2019-12-09 07:28:09.115882
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5275000000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[195   5]
 [188  12]]
Accuracy (<> F measure = f1score) is :  0.5175
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.97      0.67       200
           1       0.71      0.06      0.11       200

    accuracy                           0.52       400
   macro avg       0.61      0.52      0.39       400
weighted avg       0.61      0.52      0.39       400

F measure at 0 is :  0.6689536878216125
F measure at 1 is :  0.11059907834101382
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:28:09.115882
end clf.fit at :2019-12-09 07:28:09.131503
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.538125
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[189  11]
 [171  29]]
Accuracy (<> F measure = f1score) is :  0.545
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.53      0.94      0.67       200
           1       0.72      0.14      0.24       200

    accuracy                           0.55       400
   macro avg       0.62      0.54      0.46       400
weighted avg       0.62      0.55      0.46       400

F measure at 0 is :  0.6749999999999999
F measure at 1 is :  0.24166666666666667
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:28:09.131503
end clf.fit at :2019-12-09 07:28:09.147127
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.550625
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[184  16]
 [176  24]]
Accuracy (<> F measure = f1score) is :  0.52
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.92      0.66       200
           1       0.60      0.12      0.20       200

    accuracy                           0.52       400
   macro avg       0.56      0.52      0.43       400
weighted avg       0.56      0.52      0.43       400

F measure at 0 is :  0.6571428571428571
F measure at 1 is :  0.19999999999999998
------------ end testing the model ------------
overall_accuracy:  0.533
overall_f_measure:  0.19343696027633853
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-noise-0.9-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 7)
dataset.head(5):                 0            1                2                3                4            5  6
0   '(99.9-199.8]'  '(446-525]'  '(633.6-698.4]'  '(515.2-542.9]'    '(498-512.6]'  '(483-486]'  0
1  '(399.6-499.5]'  '(288-367]'    '(439.2-504]'  '(487.5-515.2]'  '(512.6-527.2]'  '(480-483]'  0
2  '(499.5-599.4]'  '(604-683]'    '(439.2-504]'  '(459.8-487.5]'  '(454.2-468.8]'  '(471-474]'  0
3  '(599.4-699.3]'  '(525-604]'  '(374.4-439.2]'  '(487.5-515.2]'    '(483.4-498]'  '(477-480]'  1
4  '(399.6-499.5]'  '(367-446]'  '(374.4-439.2]'  '(459.8-487.5]'  '(454.2-468.8]'  '(477-480]'  1
X_binary.shape:  (2000, 60)
start clf.fit at :2019-12-09 07:28:09.260318
end clf.fit at :2019-12-09 07:30:17.575069
clf.best_params:  {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.6287500000000001
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[134  66]
 [ 74 126]]
Accuracy (<> F measure = f1score) is :  0.65
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.64      0.67      0.66       200
           1       0.66      0.63      0.64       200

    accuracy                           0.65       400
   macro avg       0.65      0.65      0.65       400
weighted avg       0.65      0.65      0.65       400

F measure at 0 is :  0.6568627450980393
F measure at 1 is :  0.6428571428571429
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:30:17.643948
end clf.fit at :2019-12-09 07:32:22.248740
clf.best_params:  {'C': 512, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.6318750000000001
clf.best_estimator_:  SVC(C=512, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[137  63]
 [ 74 126]]
Accuracy (<> F measure = f1score) is :  0.6575
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.65      0.69      0.67       200
           1       0.67      0.63      0.65       200

    accuracy                           0.66       400
   macro avg       0.66      0.66      0.66       400
weighted avg       0.66      0.66      0.66       400

F measure at 0 is :  0.6666666666666667
F measure at 1 is :  0.6478149100257069
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:32:22.326927
end clf.fit at :2019-12-09 07:34:26.695831
clf.best_params:  {'C': 128, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.6300000000000001
clf.best_estimator_:  SVC(C=128, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[134  66]
 [ 84 116]]
Accuracy (<> F measure = f1score) is :  0.625
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.61      0.67      0.64       200
           1       0.64      0.58      0.61       200

    accuracy                           0.62       400
   macro avg       0.63      0.62      0.62       400
weighted avg       0.63      0.62      0.62       400

F measure at 0 is :  0.6411483253588517
F measure at 1 is :  0.6073298429319371
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:34:26.771473
end clf.fit at :2019-12-09 07:36:34.500961
clf.best_params:  {'C': 8192, 'gamma': 0.001953125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.63125
clf.best_estimator_:  SVC(C=8192, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.001953125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[131  69]
 [ 74 126]]
Accuracy (<> F measure = f1score) is :  0.6425
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.64      0.66      0.65       200
           1       0.65      0.63      0.64       200

    accuracy                           0.64       400
   macro avg       0.64      0.64      0.64       400
weighted avg       0.64      0.64      0.64       400

F measure at 0 is :  0.6469135802469137
F measure at 1 is :  0.6379746835443039
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:36:34.563418
end clf.fit at :2019-12-09 07:38:41.406531
clf.best_params:  {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.635
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[130  70]
 [ 69 131]]
Accuracy (<> F measure = f1score) is :  0.6525
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.65      0.65      0.65       200
           1       0.65      0.66      0.65       200

    accuracy                           0.65       400
   macro avg       0.65      0.65      0.65       400
weighted avg       0.65      0.65      0.65       400

F measure at 0 is :  0.6516290726817043
F measure at 1 is :  0.6533665835411472
------------ end testing the model ------------
overall_accuracy:  0.6455
overall_f_measure:  0.6380806533945891
start clf.fit at :2019-12-09 07:38:41.486894
end clf.fit at :2019-12-09 07:38:41.502516
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.554375
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 97 103]
 [ 71 129]]
Accuracy (<> F measure = f1score) is :  0.565
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.58      0.48      0.53       200
           1       0.56      0.65      0.60       200

    accuracy                           0.56       400
   macro avg       0.57      0.56      0.56       400
weighted avg       0.57      0.56      0.56       400

F measure at 0 is :  0.5271739130434782
F measure at 1 is :  0.5972222222222222
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:38:41.502516
end clf.fit at :2019-12-09 07:38:41.518138
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.53625
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 11 189]
 [ 15 185]]
Accuracy (<> F measure = f1score) is :  0.49
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.42      0.06      0.10       200
           1       0.49      0.93      0.64       200

    accuracy                           0.49       400
   macro avg       0.46      0.49      0.37       400
weighted avg       0.46      0.49      0.37       400

F measure at 0 is :  0.09734513274336283
F measure at 1 is :  0.6445993031358885
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:38:41.533758
end clf.fit at :2019-12-09 07:38:41.533758
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5406250000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[130  70]
 [107  93]]
Accuracy (<> F measure = f1score) is :  0.5575
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.55      0.65      0.59       200
           1       0.57      0.47      0.51       200

    accuracy                           0.56       400
   macro avg       0.56      0.56      0.55       400
weighted avg       0.56      0.56      0.55       400

F measure at 0 is :  0.5949656750572082
F measure at 1 is :  0.512396694214876
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:38:41.549379
end clf.fit at :2019-12-09 07:38:41.549379
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.55
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 33 167]
 [ 16 184]]
Accuracy (<> F measure = f1score) is :  0.5425
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.67      0.17      0.27       200
           1       0.52      0.92      0.67       200

    accuracy                           0.54       400
   macro avg       0.60      0.54      0.47       400
weighted avg       0.60      0.54      0.47       400

F measure at 0 is :  0.26506024096385544
F measure at 1 is :  0.6678765880217785
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:38:41.565001
end clf.fit at :2019-12-09 07:38:41.580624
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.530625
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[144  56]
 [126  74]]
Accuracy (<> F measure = f1score) is :  0.545
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.53      0.72      0.61       200
           1       0.57      0.37      0.45       200

    accuracy                           0.55       400
   macro avg       0.55      0.54      0.53       400
weighted avg       0.55      0.55      0.53       400

F measure at 0 is :  0.6127659574468085
F measure at 1 is :  0.44848484848484843
------------ end testing the model ------------
overall_accuracy:  0.54
overall_f_measure:  0.5911111111111111
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-noise-1.0-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 9)
dataset.head(5):                 0            1                2                3                4                5                6                7  8
0   '(99.9-199.8]'  '(446-525]'  '(633.6-698.4]'  '(580.2-642.4]'  '(445.5-517.8]'  '(601.8-657.2]'  '(433.4-464.1]'  '(465.2-470.3]'  0
1  '(399.6-499.5]'  '(288-367]'    '(439.2-504]'    '(518-580.2]'  '(300.9-373.2]'    '(435.6-491]'  '(525.5-556.2]'  '(480.5-485.6]'  0
2  '(499.5-599.4]'  '(604-683]'    '(439.2-504]'  '(393.6-455.8]'  '(590.1-662.4]'    '(435.6-491]'  '(464.1-494.8]'  '(475.4-480.5]'  0
3  '(599.4-699.3]'  '(525-604]'  '(374.4-439.2]'  '(331.4-393.6]'  '(517.8-590.1]'  '(380.2-435.6]'  '(494.8-525.5]'  '(480.5-485.6]'  1
4  '(399.6-499.5]'  '(367-446]'  '(374.4-439.2]'    '(455.8-518]'  '(373.2-445.5]'  '(380.2-435.6]'  '(494.8-525.5]'  '(480.5-485.6]'  1
X_binary.shape:  (2000, 80)
start clf.fit at :2019-12-09 07:38:41.710189
end clf.fit at :2019-12-09 07:40:48.719671
clf.best_params:  {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.6899999999999998
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[141  59]
 [ 56 144]]
Accuracy (<> F measure = f1score) is :  0.7125
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.72      0.70      0.71       200
           1       0.71      0.72      0.71       200

    accuracy                           0.71       400
   macro avg       0.71      0.71      0.71       400
weighted avg       0.71      0.71      0.71       400

F measure at 0 is :  0.7103274559193954
F measure at 1 is :  0.7146401985111662
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:40:48.803263
end clf.fit at :2019-12-09 07:42:55.868864
clf.best_params:  {'C': 32, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.685
clf.best_estimator_:  SVC(C=32, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[141  59]
 [ 62 138]]
Accuracy (<> F measure = f1score) is :  0.6975
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.69      0.70      0.70       200
           1       0.70      0.69      0.70       200

    accuracy                           0.70       400
   macro avg       0.70      0.70      0.70       400
weighted avg       0.70      0.70      0.70       400

F measure at 0 is :  0.6997518610421837
F measure at 1 is :  0.6952141057934508
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:42:55.957654
end clf.fit at :2019-12-09 07:45:01.283697
clf.best_params:  {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.681875
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[145  55]
 [ 68 132]]
Accuracy (<> F measure = f1score) is :  0.6925
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.68      0.72      0.70       200
           1       0.71      0.66      0.68       200

    accuracy                           0.69       400
   macro avg       0.69      0.69      0.69       400
weighted avg       0.69      0.69      0.69       400

F measure at 0 is :  0.702179176755448
F measure at 1 is :  0.6821705426356589
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:45:01.375666
end clf.fit at :2019-12-09 07:47:09.313776
clf.best_params:  {'C': 8, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.67625
clf.best_estimator_:  SVC(C=8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[146  54]
 [ 66 134]]
Accuracy (<> F measure = f1score) is :  0.7
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.69      0.73      0.71       200
           1       0.71      0.67      0.69       200

    accuracy                           0.70       400
   macro avg       0.70      0.70      0.70       400
weighted avg       0.70      0.70      0.70       400

F measure at 0 is :  0.7087378640776699
F measure at 1 is :  0.6907216494845361
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:47:09.413839
end clf.fit at :2019-12-09 07:49:18.647169
clf.best_params:  {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.688125
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[139  61]
 [ 55 145]]
Accuracy (<> F measure = f1score) is :  0.71
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.72      0.69      0.71       200
           1       0.70      0.72      0.71       200

    accuracy                           0.71       400
   macro avg       0.71      0.71      0.71       400
weighted avg       0.71      0.71      0.71       400

F measure at 0 is :  0.7055837563451777
F measure at 1 is :  0.7142857142857142
------------ end testing the model ------------
overall_accuracy:  0.7025
overall_f_measure:  0.6996466431095406
start clf.fit at :2019-12-09 07:49:18.740867
end clf.fit at :2019-12-09 07:49:18.756492
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.56375
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 46 154]
 [ 32 168]]
Accuracy (<> F measure = f1score) is :  0.535
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.59      0.23      0.33       200
           1       0.52      0.84      0.64       200

    accuracy                           0.54       400
   macro avg       0.56      0.54      0.49       400
weighted avg       0.56      0.54      0.49       400

F measure at 0 is :  0.33093525179856115
F measure at 1 is :  0.6436781609195402
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:49:18.756492
end clf.fit at :2019-12-09 07:49:18.772112
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.55625
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[137  63]
 [ 92 108]]
Accuracy (<> F measure = f1score) is :  0.6125
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.60      0.69      0.64       200
           1       0.63      0.54      0.58       200

    accuracy                           0.61       400
   macro avg       0.61      0.61      0.61       400
weighted avg       0.61      0.61      0.61       400

F measure at 0 is :  0.6386946386946387
F measure at 1 is :  0.5822102425876011
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:49:18.772112
end clf.fit at :2019-12-09 07:49:18.787731
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5325
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 57 143]
 [ 27 173]]
Accuracy (<> F measure = f1score) is :  0.575
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.68      0.28      0.40       200
           1       0.55      0.86      0.67       200

    accuracy                           0.57       400
   macro avg       0.61      0.57      0.54       400
weighted avg       0.61      0.57      0.54       400

F measure at 0 is :  0.4014084507042254
F measure at 1 is :  0.6705426356589148
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:49:18.803354
end clf.fit at :2019-12-09 07:49:18.803354
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.573125
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 61 139]
 [ 28 172]]
Accuracy (<> F measure = f1score) is :  0.5825
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.69      0.30      0.42       200
           1       0.55      0.86      0.67       200

    accuracy                           0.58       400
   macro avg       0.62      0.58      0.55       400
weighted avg       0.62      0.58      0.55       400

F measure at 0 is :  0.42214532871972316
F measure at 1 is :  0.6731898238747553
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:49:18.818974
end clf.fit at :2019-12-09 07:49:18.834599
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.566875
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[157  43]
 [136  64]]
Accuracy (<> F measure = f1score) is :  0.5525
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.54      0.79      0.64       200
           1       0.60      0.32      0.42       200

    accuracy                           0.55       400
   macro avg       0.57      0.55      0.53       400
weighted avg       0.57      0.55      0.53       400

F measure at 0 is :  0.6369168356997972
F measure at 1 is :  0.4169381107491857
------------ end testing the model ------------
overall_accuracy:  0.5715
overall_f_measure:  0.6151773686573866
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-ratio-0.5-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 6)
dataset.head(5):                 0                1                2                3              4  5
0  '(442.4-467.2]'    '(485-503.2]'  '(477.4-486.5]'  '(475.6-483.5]'  '(477.5-479]'  0
1  '(516.8-541.6]'  '(503.2-521.4]'  '(477.4-486.5]'  '(499.3-507.2]'  '(476-477.5]'  0
2  '(516.8-541.6]'    '(485-503.2]'  '(477.4-486.5]'  '(483.5-491.4]'  '(476-477.5]'  0
3  '(541.6-566.4]'  '(521.4-539.6]'  '(477.4-486.5]'  '(467.7-475.6]'  '(477.5-479]'  1
4  '(442.4-467.2]'  '(503.2-521.4]'  '(495.6-504.7]'  '(475.6-483.5]'  '(477.5-479]'  1
X_binary.shape:  (2000, 50)
start clf.fit at :2019-12-09 07:49:18.922165
end clf.fit at :2019-12-09 07:51:45.617025
clf.best_params:  {'C': 32, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.5162500000000001
clf.best_estimator_:  SVC(C=32, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 99 101]
 [101  99]]
Accuracy (<> F measure = f1score) is :  0.495
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.49      0.49      0.49       200
           1       0.49      0.49      0.49       200

    accuracy                           0.49       400
   macro avg       0.49      0.49      0.49       400
weighted avg       0.49      0.49      0.49       400

F measure at 0 is :  0.495
F measure at 1 is :  0.495
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:51:45.689577
end clf.fit at :2019-12-09 07:54:08.375652
clf.best_params:  {'C': 0.03125, 'gamma': 3.0517578125e-05, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.5112500000000001
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=3.0517578125e-05,
    kernel='rbf', max_iter=-1, probability=False, random_state=None,
    shrinking=True, tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[141  59]
 [139  61]]
Accuracy (<> F measure = f1score) is :  0.505
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.70      0.59       200
           1       0.51      0.30      0.38       200

    accuracy                           0.51       400
   macro avg       0.51      0.51      0.48       400
weighted avg       0.51      0.51      0.48       400

F measure at 0 is :  0.5874999999999999
F measure at 1 is :  0.38125000000000003
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:54:08.444069
end clf.fit at :2019-12-09 07:56:36.495707
clf.best_params:  {'C': 2048, 'gamma': 3.0517578125e-05, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.523125
clf.best_estimator_:  SVC(C=2048, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=3.0517578125e-05,
    kernel='rbf', max_iter=-1, probability=False, random_state=None,
    shrinking=True, tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 99 101]
 [ 97 103]]
Accuracy (<> F measure = f1score) is :  0.505
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.49      0.50       200
           1       0.50      0.52      0.51       200

    accuracy                           0.51       400
   macro avg       0.51      0.51      0.50       400
weighted avg       0.51      0.51      0.50       400

F measure at 0 is :  0.5
F measure at 1 is :  0.5099009900990098
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:56:36.574322
end clf.fit at :2019-12-09 07:59:08.634447
clf.best_params:  {'C': 512, 'gamma': 0.001953125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.5293749999999999
clf.best_estimator_:  SVC(C=512, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.001953125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[110  90]
 [103  97]]
Accuracy (<> F measure = f1score) is :  0.5175
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.52      0.55      0.53       200
           1       0.52      0.48      0.50       200

    accuracy                           0.52       400
   macro avg       0.52      0.52      0.52       400
weighted avg       0.52      0.52      0.52       400

F measure at 0 is :  0.5326876513317191
F measure at 1 is :  0.5012919896640826
------------ end testing the model ------------
start clf.fit at :2019-12-09 07:59:08.696934
end clf.fit at :2019-12-09 08:01:36.498056
clf.best_params:  {'C': 2, 'gamma': 8, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.514375
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=8, kernel='rbf', max_iter=-1,
    probability=False, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 35 165]
 [ 28 172]]
Accuracy (<> F measure = f1score) is :  0.5175
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.56      0.17      0.27       200
           1       0.51      0.86      0.64       200

    accuracy                           0.52       400
   macro avg       0.53      0.52      0.45       400
weighted avg       0.53      0.52      0.45       400

F measure at 0 is :  0.2661596958174905
F measure at 1 is :  0.6405959031657356
------------ end testing the model ------------
overall_accuracy:  0.508
overall_f_measure:  0.51953125
start clf.fit at :2019-12-09 08:01:36.571448
end clf.fit at :2019-12-09 08:01:36.571448
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.499375
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[195   5]
 [189  11]]
Accuracy (<> F measure = f1score) is :  0.515
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.97      0.67       200
           1       0.69      0.06      0.10       200

    accuracy                           0.52       400
   macro avg       0.60      0.52      0.38       400
weighted avg       0.60      0.52      0.38       400

F measure at 0 is :  0.6678082191780822
F measure at 1 is :  0.10185185185185185
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:01:36.587072
end clf.fit at :2019-12-09 08:01:36.602696
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.50625
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 11 189]
 [ 18 182]]
Accuracy (<> F measure = f1score) is :  0.4825
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.38      0.06      0.10       200
           1       0.49      0.91      0.64       200

    accuracy                           0.48       400
   macro avg       0.43      0.48      0.37       400
weighted avg       0.43      0.48      0.37       400

F measure at 0 is :  0.09606986899563319
F measure at 1 is :  0.6374781085814362
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:01:36.602696
end clf.fit at :2019-12-09 08:01:36.618317
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.49437499999999995
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[192   8]
 [194   6]]
Accuracy (<> F measure = f1score) is :  0.495
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.96      0.66       200
           1       0.43      0.03      0.06       200

    accuracy                           0.49       400
   macro avg       0.46      0.49      0.36       400
weighted avg       0.46      0.49      0.36       400

F measure at 0 is :  0.6552901023890785
F measure at 1 is :  0.056074766355140186
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:01:36.618317
end clf.fit at :2019-12-09 08:01:36.633940
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5075000000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[189  11]
 [189  11]]
Accuracy (<> F measure = f1score) is :  0.5
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.94      0.65       200
           1       0.50      0.06      0.10       200

    accuracy                           0.50       400
   macro avg       0.50      0.50      0.38       400
weighted avg       0.50      0.50      0.38       400

F measure at 0 is :  0.6539792387543253
F measure at 1 is :  0.09909909909909909
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:01:36.649567
end clf.fit at :2019-12-09 08:01:36.649567
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5062499999999999
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 54 146]
 [ 55 145]]
Accuracy (<> F measure = f1score) is :  0.4975
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.27      0.35       200
           1       0.50      0.72      0.59       200

    accuracy                           0.50       400
   macro avg       0.50      0.50      0.47       400
weighted avg       0.50      0.50      0.47       400

F measure at 0 is :  0.3495145631067962
F measure at 1 is :  0.5906313645621181
------------ end testing the model ------------
overall_accuracy:  0.498
overall_f_measure:  0.41423570595099185
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-ratio-0.6-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 6)
dataset.head(5):                 0                1                2                3                4  5
0  '(456.2-482.6]'  '(526.2-544.6]'  '(508.2-523.4]'  '(460.9-473.2]'  '(469.9-475.2]'  0
1    '(509-535.4]'  '(489.4-507.8]'  '(447.4-462.6]'  '(497.8-510.1]'  '(469.9-475.2]'  0
2  '(429.8-456.2]'    '(452.6-471]'    '(493-508.2]'  '(497.8-510.1]'  '(469.9-475.2]'  0
3    '(509-535.4]'    '(471-489.4]'  '(462.6-477.8]'  '(485.5-497.8]'  '(475.2-480.5]'  1
4  '(429.8-456.2]'    '(471-489.4]'    '(493-508.2]'  '(473.2-485.5]'  '(469.9-475.2]'  1
X_binary.shape:  (2000, 50)
start clf.fit at :2019-12-09 08:01:36.750666
end clf.fit at :2019-12-09 08:04:03.489546
clf.best_params:  {'C': 8, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.524375
clf.best_estimator_:  SVC(C=8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 89 111]
 [ 94 106]]
Accuracy (<> F measure = f1score) is :  0.4875
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.49      0.45      0.46       200
           1       0.49      0.53      0.51       200

    accuracy                           0.49       400
   macro avg       0.49      0.49      0.49       400
weighted avg       0.49      0.49      0.49       400

F measure at 0 is :  0.4647519582245431
F measure at 1 is :  0.5083932853717026
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:04:03.566872
end clf.fit at :2019-12-09 08:06:37.578911
clf.best_params:  {'C': 8192, 'gamma': 0.0001220703125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.526875
clf.best_estimator_:  SVC(C=8192, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0001220703125,
    kernel='rbf', max_iter=-1, probability=False, random_state=None,
    shrinking=True, tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[103  97]
 [100 100]]
Accuracy (<> F measure = f1score) is :  0.5075
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.52      0.51       200
           1       0.51      0.50      0.50       200

    accuracy                           0.51       400
   macro avg       0.51      0.51      0.51       400
weighted avg       0.51      0.51      0.51       400

F measure at 0 is :  0.511166253101737
F measure at 1 is :  0.5037783375314862
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:06:37.645147
end clf.fit at :2019-12-09 08:09:05.732686
clf.best_params:  {'C': 0.5, 'gamma': 2, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.525
clf.best_estimator_:  SVC(C=0.5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf', max_iter=-1,
    probability=False, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 45 155]
 [ 42 158]]
Accuracy (<> F measure = f1score) is :  0.5075
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.52      0.23      0.31       200
           1       0.50      0.79      0.62       200

    accuracy                           0.51       400
   macro avg       0.51      0.51      0.46       400
weighted avg       0.51      0.51      0.46       400

F measure at 0 is :  0.31358885017421606
F measure at 1 is :  0.6159844054580896
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:09:05.812171
end clf.fit at :2019-12-09 08:11:35.114866
clf.best_params:  {'C': 128, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.51375
clf.best_estimator_:  SVC(C=128, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[109  91]
 [ 98 102]]
Accuracy (<> F measure = f1score) is :  0.5275
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.53      0.55      0.54       200
           1       0.53      0.51      0.52       200

    accuracy                           0.53       400
   macro avg       0.53      0.53      0.53       400
weighted avg       0.53      0.53      0.53       400

F measure at 0 is :  0.5356265356265356
F measure at 1 is :  0.5190839694656488
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:11:35.182218
end clf.fit at :2019-12-09 08:14:08.022074
clf.best_params:  {'C': 8, 'gamma': 0.5, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.530625
clf.best_estimator_:  SVC(C=8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 95 105]
 [102  98]]
Accuracy (<> F measure = f1score) is :  0.4825
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.48      0.47      0.48       200
           1       0.48      0.49      0.49       200

    accuracy                           0.48       400
   macro avg       0.48      0.48      0.48       400
weighted avg       0.48      0.48      0.48       400

F measure at 0 is :  0.4785894206549118
F measure at 1 is :  0.48635235732009924
------------ end testing the model ------------
overall_accuracy:  0.5025
overall_f_measure:  0.5313235986811117
start clf.fit at :2019-12-09 08:14:08.096451
end clf.fit at :2019-12-09 08:14:08.096451
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.49749999999999994
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[187  13]
 [184  16]]
Accuracy (<> F measure = f1score) is :  0.5075
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.94      0.65       200
           1       0.55      0.08      0.14       200

    accuracy                           0.51       400
   macro avg       0.53      0.51      0.40       400
weighted avg       0.53      0.51      0.40       400

F measure at 0 is :  0.6549912434325744
F measure at 1 is :  0.13973799126637557
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:14:08.112078
end clf.fit at :2019-12-09 08:14:08.112078
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.505625
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[193   7]
 [191   9]]
Accuracy (<> F measure = f1score) is :  0.505
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.96      0.66       200
           1       0.56      0.04      0.08       200

    accuracy                           0.51       400
   macro avg       0.53      0.51      0.37       400
weighted avg       0.53      0.51      0.37       400

F measure at 0 is :  0.660958904109589
F measure at 1 is :  0.08333333333333333
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:14:08.127696
end clf.fit at :2019-12-09 08:14:08.143320
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.50875
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[135  65]
 [128  72]]
Accuracy (<> F measure = f1score) is :  0.5175
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.68      0.58       200
           1       0.53      0.36      0.43       200

    accuracy                           0.52       400
   macro avg       0.52      0.52      0.51       400
weighted avg       0.52      0.52      0.51       400

F measure at 0 is :  0.5831533477321813
F measure at 1 is :  0.42729970326409494
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:14:08.143320
end clf.fit at :2019-12-09 08:14:08.158944
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5075000000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[198   2]
 [197   3]]
Accuracy (<> F measure = f1score) is :  0.5025
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.99      0.67       200
           1       0.60      0.01      0.03       200

    accuracy                           0.50       400
   macro avg       0.55      0.50      0.35       400
weighted avg       0.55      0.50      0.35       400

F measure at 0 is :  0.6655462184873949
F measure at 1 is :  0.029268292682926828
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:14:08.158944
end clf.fit at :2019-12-09 08:14:08.174563
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[190  10]
 [189  11]]
Accuracy (<> F measure = f1score) is :  0.5025
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.95      0.66       200
           1       0.52      0.06      0.10       200

    accuracy                           0.50       400
   macro avg       0.51      0.50      0.38       400
weighted avg       0.51      0.50      0.38       400

F measure at 0 is :  0.6563039723661485
F measure at 1 is :  0.09954751131221719
------------ end testing the model ------------
overall_accuracy:  0.507
overall_f_measure:  0.1837748344370861
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-ratio-0.7-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 6)
dataset.head(5):                 0            1                2                3                4  5
0  '(460.1-487.8]'  '(455-483]'  '(482.8-504.5]'    '(471.2-487]'    '(487-494.4]'  0
1  '(515.5-543.2]'  '(399-427]'  '(547.9-569.6]'    '(487-502.8]'    '(479.6-487]'  0
2  '(460.1-487.8]'  '(511-539]'  '(461.1-482.8]'  '(502.8-518.6]'  '(464.8-472.2]'  0
3  '(487.8-515.5]'  '(511-539]'  '(482.8-504.5]'    '(487-502.8]'  '(472.2-479.6]'  1
4  '(570.9-598.6]'  '(455-483]'  '(526.2-547.9]'  '(455.4-471.2]'    '(479.6-487]'  1
X_binary.shape:  (2000, 50)
start clf.fit at :2019-12-09 08:14:08.271808
end clf.fit at :2019-12-09 08:16:28.443458
clf.best_params:  {'C': 8, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.5118750000000001
clf.best_estimator_:  SVC(C=8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 94 106]
 [ 99 101]]
Accuracy (<> F measure = f1score) is :  0.4875
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.49      0.47      0.48       200
           1       0.49      0.51      0.50       200

    accuracy                           0.49       400
   macro avg       0.49      0.49      0.49       400
weighted avg       0.49      0.49      0.49       400

F measure at 0 is :  0.47837150127226463
F measure at 1 is :  0.49631449631449626
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:16:28.509553
end clf.fit at :2019-12-09 08:18:49.810187
clf.best_params:  {'C': 0.5, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.51625
clf.best_estimator_:  SVC(C=0.5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 84 116]
 [ 89 111]]
Accuracy (<> F measure = f1score) is :  0.4875
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.49      0.42      0.45       200
           1       0.49      0.56      0.52       200

    accuracy                           0.49       400
   macro avg       0.49      0.49      0.49       400
weighted avg       0.49      0.49      0.49       400

F measure at 0 is :  0.450402144772118
F measure at 1 is :  0.5199063231850117
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:18:49.888807
end clf.fit at :2019-12-09 08:21:09.996280
clf.best_params:  {'C': 2, 'gamma': 8, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.4925
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=8, kernel='rbf', max_iter=-1,
    probability=False, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[174  26]
 [167  33]]
Accuracy (<> F measure = f1score) is :  0.5175
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.87      0.64       200
           1       0.56      0.17      0.25       200

    accuracy                           0.52       400
   macro avg       0.53      0.52      0.45       400
weighted avg       0.53      0.52      0.45       400

F measure at 0 is :  0.643253234750462
F measure at 1 is :  0.2548262548262548
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:21:10.074381
end clf.fit at :2019-12-09 08:23:32.620696
clf.best_params:  {'C': 0.03125, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.5081249999999999
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[107  93]
 [111  89]]
Accuracy (<> F measure = f1score) is :  0.49
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.49      0.54      0.51       200
           1       0.49      0.45      0.47       200

    accuracy                           0.49       400
   macro avg       0.49      0.49      0.49       400
weighted avg       0.49      0.49      0.49       400

F measure at 0 is :  0.5119617224880384
F measure at 1 is :  0.46596858638743455
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:23:32.698798
end clf.fit at :2019-12-09 08:25:54.442335
clf.best_params:  {'C': 32768, 'gamma': 0.001953125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.51
clf.best_estimator_:  SVC(C=32768, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.001953125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 88 112]
 [ 94 106]]
Accuracy (<> F measure = f1score) is :  0.485
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.48      0.44      0.46       200
           1       0.49      0.53      0.51       200

    accuracy                           0.48       400
   macro avg       0.48      0.48      0.48       400
weighted avg       0.48      0.48      0.48       400

F measure at 0 is :  0.46073298429319376
F measure at 1 is :  0.5071770334928231
------------ end testing the model ------------
overall_accuracy:  0.4935
overall_f_measure:  0.4648705758055996
start clf.fit at :2019-12-09 08:25:54.504792
end clf.fit at :2019-12-09 08:25:54.521961
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.49750000000000005
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[  4 196]
 [  5 195]]
Accuracy (<> F measure = f1score) is :  0.4975
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.44      0.02      0.04       200
           1       0.50      0.97      0.66       200

    accuracy                           0.50       400
   macro avg       0.47      0.50      0.35       400
weighted avg       0.47      0.50      0.35       400

F measure at 0 is :  0.03827751196172249
F measure at 1 is :  0.6598984771573604
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:25:54.521961
end clf.fit at :2019-12-09 08:25:54.537586
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.49874999999999997
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[  4 196]
 [  3 197]]
Accuracy (<> F measure = f1score) is :  0.5025
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.57      0.02      0.04       200
           1       0.50      0.98      0.66       200

    accuracy                           0.50       400
   macro avg       0.54      0.50      0.35       400
weighted avg       0.54      0.50      0.35       400

F measure at 0 is :  0.03864734299516908
F measure at 1 is :  0.6644182124789206
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:25:54.557072
end clf.fit at :2019-12-09 08:25:54.557243
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.496875
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[  8 192]
 [  7 193]]
Accuracy (<> F measure = f1score) is :  0.5025
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.53      0.04      0.07       200
           1       0.50      0.96      0.66       200

    accuracy                           0.50       400
   macro avg       0.52      0.50      0.37       400
weighted avg       0.52      0.50      0.37       400

F measure at 0 is :  0.07441860465116279
F measure at 1 is :  0.6598290598290597
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:25:54.572946
end clf.fit at :2019-12-09 08:25:54.588568
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.49437499999999995
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[  8 192]
 [ 10 190]]
Accuracy (<> F measure = f1score) is :  0.495
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.44      0.04      0.07       200
           1       0.50      0.95      0.65       200

    accuracy                           0.49       400
   macro avg       0.47      0.49      0.36       400
weighted avg       0.47      0.49      0.36       400

F measure at 0 is :  0.07339449541284404
F measure at 1 is :  0.6529209621993126
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:25:54.588568
end clf.fit at :2019-12-09 08:25:54.604189
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.500625
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[  6 194]
 [  9 191]]
Accuracy (<> F measure = f1score) is :  0.4925
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.40      0.03      0.06       200
           1       0.50      0.95      0.65       200

    accuracy                           0.49       400
   macro avg       0.45      0.49      0.35       400
weighted avg       0.45      0.49      0.35       400

F measure at 0 is :  0.055813953488372085
F measure at 1 is :  0.652991452991453
------------ end testing the model ------------
overall_accuracy:  0.498
overall_f_measure:  0.6580381471389646
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-ratio-0.8-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 6)
dataset.head(5):                 0                1            2                3            4  5
0   '(99.9-199.8]'  '(516.5-543.4]'  '(455-483]'    '(487-507.8]'  '(442-451]'  0
1  '(399.6-499.5]'  '(435.8-462.7]'  '(399-427]'  '(507.8-528.6]'  '(460-469]'  0
2  '(499.5-599.4]'  '(462.7-489.6]'  '(511-539]'  '(528.6-549.4]'  '(460-469]'  0
3  '(599.4-699.3]'  '(462.7-489.6]'  '(511-539]'  '(507.8-528.6]'  '(496-505]'  1
4  '(399.6-499.5]'  '(570.3-597.2]'  '(455-483]'  '(507.8-528.6]'  '(478-487]'  1
X_binary.shape:  (2000, 50)
start clf.fit at :2019-12-09 08:25:54.696702
end clf.fit at :2019-12-09 08:28:14.179742
clf.best_params:  {'C': 128, 'gamma': 0.001953125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.555
clf.best_estimator_:  SVC(C=128, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.001953125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[139  61]
 [110  90]]
Accuracy (<> F measure = f1score) is :  0.5725
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.56      0.69      0.62       200
           1       0.60      0.45      0.51       200

    accuracy                           0.57       400
   macro avg       0.58      0.57      0.57       400
weighted avg       0.58      0.57      0.57       400

F measure at 0 is :  0.6191536748329621
F measure at 1 is :  0.5128205128205129
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:28:14.259016
end clf.fit at :2019-12-09 08:30:31.427459
clf.best_params:  {'C': 512, 'gamma': 0.00048828125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.555
clf.best_estimator_:  SVC(C=512, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.00048828125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[142  58]
 [106  94]]
Accuracy (<> F measure = f1score) is :  0.59
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.57      0.71      0.63       200
           1       0.62      0.47      0.53       200

    accuracy                           0.59       400
   macro avg       0.60      0.59      0.58       400
weighted avg       0.60      0.59      0.58       400

F measure at 0 is :  0.6339285714285714
F measure at 1 is :  0.5340909090909091
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:30:31.503873
end clf.fit at :2019-12-09 08:32:49.038885
clf.best_params:  {'C': 8, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.559375
clf.best_estimator_:  SVC(C=8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[129  71]
 [104  96]]
Accuracy (<> F measure = f1score) is :  0.5625
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.55      0.65      0.60       200
           1       0.57      0.48      0.52       200

    accuracy                           0.56       400
   macro avg       0.56      0.56      0.56       400
weighted avg       0.56      0.56      0.56       400

F measure at 0 is :  0.5958429561200924
F measure at 1 is :  0.5231607629427792
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:32:49.101992
end clf.fit at :2019-12-09 08:35:08.238863
clf.best_params:  {'C': 512, 'gamma': 0.00048828125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.548125
clf.best_estimator_:  SVC(C=512, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.00048828125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[149  51]
 [118  82]]
Accuracy (<> F measure = f1score) is :  0.5775
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.56      0.74      0.64       200
           1       0.62      0.41      0.49       200

    accuracy                           0.58       400
   macro avg       0.59      0.58      0.57       400
weighted avg       0.59      0.58      0.57       400

F measure at 0 is :  0.6381156316916489
F measure at 1 is :  0.4924924924924924
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:35:08.313077
end clf.fit at :2019-12-09 08:37:28.987456
clf.best_params:  {'C': 8192, 'gamma': 0.00048828125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.5762499999999999
clf.best_estimator_:  SVC(C=8192, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.00048828125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[147  53]
 [126  74]]
Accuracy (<> F measure = f1score) is :  0.5525
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.54      0.73      0.62       200
           1       0.58      0.37      0.45       200

    accuracy                           0.55       400
   macro avg       0.56      0.55      0.54       400
weighted avg       0.56      0.55      0.54       400

F measure at 0 is :  0.6215644820295984
F measure at 1 is :  0.4525993883792049
------------ end testing the model ------------
overall_accuracy:  0.571
overall_f_measure:  0.5040462427745664
start clf.fit at :2019-12-09 08:37:29.049920
end clf.fit at :2019-12-09 08:37:29.065547
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.541875
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[178  22]
 [159  41]]
Accuracy (<> F measure = f1score) is :  0.5475
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.53      0.89      0.66       200
           1       0.65      0.20      0.31       200

    accuracy                           0.55       400
   macro avg       0.59      0.55      0.49       400
weighted avg       0.59      0.55      0.49       400

F measure at 0 is :  0.6629422718808194
F measure at 1 is :  0.311787072243346
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:37:29.065547
end clf.fit at :2019-12-09 08:37:29.081162
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5387500000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[177  23]
 [146  54]]
Accuracy (<> F measure = f1score) is :  0.5775
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.55      0.89      0.68       200
           1       0.70      0.27      0.39       200

    accuracy                           0.58       400
   macro avg       0.62      0.58      0.53       400
weighted avg       0.62      0.58      0.53       400

F measure at 0 is :  0.6768642447418738
F measure at 1 is :  0.3898916967509025
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:37:29.098887
end clf.fit at :2019-12-09 08:37:29.098887
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5537500000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[185  15]
 [163  37]]
Accuracy (<> F measure = f1score) is :  0.555
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.53      0.93      0.68       200
           1       0.71      0.18      0.29       200

    accuracy                           0.56       400
   macro avg       0.62      0.56      0.48       400
weighted avg       0.62      0.56      0.48       400

F measure at 0 is :  0.6751824817518248
F measure at 1 is :  0.29365079365079366
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:37:29.114640
end clf.fit at :2019-12-09 08:37:29.114640
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5025
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[  5 195]
 [  7 193]]
Accuracy (<> F measure = f1score) is :  0.495
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.42      0.03      0.05       200
           1       0.50      0.96      0.66       200

    accuracy                           0.49       400
   macro avg       0.46      0.49      0.35       400
weighted avg       0.46      0.49      0.35       400

F measure at 0 is :  0.04716981132075472
F measure at 1 is :  0.6564625850340137
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:37:29.130261
end clf.fit at :2019-12-09 08:37:29.130261
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5431250000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[188  12]
 [171  29]]
Accuracy (<> F measure = f1score) is :  0.5425
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.52      0.94      0.67       200
           1       0.71      0.14      0.24       200

    accuracy                           0.54       400
   macro avg       0.62      0.54      0.46       400
weighted avg       0.62      0.54      0.46       400

F measure at 0 is :  0.6726296958855098
F measure at 1 is :  0.24066390041493774
------------ end testing the model ------------
overall_accuracy:  0.5435
overall_f_measure:  0.4367674275138803
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-ratio-0.9-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 7)
dataset.head(5):                 0            1                2                3                4                5  6
0   '(99.9-199.8]'  '(446-525]'  '(633.6-698.4]'  '(433.8-460.4]'    '(498-512.6]'  '(454.4-462.6]'  0
1  '(399.6-499.5]'  '(288-367]'    '(439.2-504]'  '(433.8-460.4]'  '(512.6-527.2]'    '(470.8-479]'  0
2  '(499.5-599.4]'  '(604-683]'    '(439.2-504]'    '(460.4-487]'  '(454.2-468.8]'  '(487.2-495.4]'  0
3  '(599.4-699.3]'  '(525-604]'  '(374.4-439.2]'  '(433.8-460.4]'    '(483.4-498]'    '(470.8-479]'  1
4  '(399.6-499.5]'  '(367-446]'  '(374.4-439.2]'  '(407.2-433.8]'  '(454.2-468.8]'    '(470.8-479]'  1
X_binary.shape:  (2000, 60)
start clf.fit at :2019-12-09 08:37:29.248533
end clf.fit at :2019-12-09 08:39:25.791261
clf.best_params:  {'C': 8, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.7012499999999999
clf.best_estimator_:  SVC(C=8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[133  67]
 [ 70 130]]
Accuracy (<> F measure = f1score) is :  0.6575
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.66      0.67      0.66       200
           1       0.66      0.65      0.65       200

    accuracy                           0.66       400
   macro avg       0.66      0.66      0.66       400
weighted avg       0.66      0.66      0.66       400

F measure at 0 is :  0.6600496277915633
F measure at 1 is :  0.6549118387909321
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:39:25.853746
end clf.fit at :2019-12-09 08:41:20.086388
clf.best_params:  {'C': 8, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.675625
clf.best_estimator_:  SVC(C=8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[138  62]
 [ 62 138]]
Accuracy (<> F measure = f1score) is :  0.69
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.69      0.69      0.69       200
           1       0.69      0.69      0.69       200

    accuracy                           0.69       400
   macro avg       0.69      0.69      0.69       400
weighted avg       0.69      0.69      0.69       400

F measure at 0 is :  0.69
F measure at 1 is :  0.69
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:41:20.142143
end clf.fit at :2019-12-09 08:43:15.019860
clf.best_params:  {'C': 8, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.675
clf.best_estimator_:  SVC(C=8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[146  54]
 [ 58 142]]
Accuracy (<> F measure = f1score) is :  0.72
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.72      0.73      0.72       200
           1       0.72      0.71      0.72       200

    accuracy                           0.72       400
   macro avg       0.72      0.72      0.72       400
weighted avg       0.72      0.72      0.72       400

F measure at 0 is :  0.7227722772277227
F measure at 1 is :  0.7171717171717172
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:43:15.075642
end clf.fit at :2019-12-09 08:45:12.262213
clf.best_params:  {'C': 8192, 'gamma': 0.001953125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.6756249999999999
clf.best_estimator_:  SVC(C=8192, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.001953125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[142  58]
 [ 69 131]]
Accuracy (<> F measure = f1score) is :  0.6825
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.67      0.71      0.69       200
           1       0.69      0.66      0.67       200

    accuracy                           0.68       400
   macro avg       0.68      0.68      0.68       400
weighted avg       0.68      0.68      0.68       400

F measure at 0 is :  0.6909975669099756
F measure at 1 is :  0.6735218508997429
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:45:12.310737
end clf.fit at :2019-12-09 08:47:09.374652
clf.best_params:  {'C': 8, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.689375
clf.best_estimator_:  SVC(C=8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[133  67]
 [ 65 135]]
Accuracy (<> F measure = f1score) is :  0.67
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.67      0.67      0.67       200
           1       0.67      0.68      0.67       200

    accuracy                           0.67       400
   macro avg       0.67      0.67      0.67       400
weighted avg       0.67      0.67      0.67       400

F measure at 0 is :  0.6683417085427136
F measure at 1 is :  0.6716417910447763
------------ end testing the model ------------
overall_accuracy:  0.684
overall_f_measure:  0.6814516129032258
start clf.fit at :2019-12-09 08:47:09.428822
end clf.fit at :2019-12-09 08:47:09.444478
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5525
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[197   3]
 [167  33]]
Accuracy (<> F measure = f1score) is :  0.575
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.54      0.98      0.70       200
           1       0.92      0.17      0.28       200

    accuracy                           0.57       400
   macro avg       0.73      0.57      0.49       400
weighted avg       0.73      0.57      0.49       400

F measure at 0 is :  0.6985815602836878
F measure at 1 is :  0.2796610169491526
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:47:09.460096
end clf.fit at :2019-12-09 08:47:09.460096
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.56375
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[156  44]
 [122  78]]
Accuracy (<> F measure = f1score) is :  0.585
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.56      0.78      0.65       200
           1       0.64      0.39      0.48       200

    accuracy                           0.58       400
   macro avg       0.60      0.58      0.57       400
weighted avg       0.60      0.58      0.57       400

F measure at 0 is :  0.6527196652719666
F measure at 1 is :  0.48447204968944096
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:47:09.475719
end clf.fit at :2019-12-09 08:47:09.491340
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.546875
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[189  11]
 [167  33]]
Accuracy (<> F measure = f1score) is :  0.555
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.53      0.94      0.68       200
           1       0.75      0.17      0.27       200

    accuracy                           0.56       400
   macro avg       0.64      0.55      0.48       400
weighted avg       0.64      0.56      0.48       400

F measure at 0 is :  0.6798561151079137
F measure at 1 is :  0.2704918032786885
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:47:09.491340
end clf.fit at :2019-12-09 08:47:09.506964
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.540625
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[156  44]
 [124  76]]
Accuracy (<> F measure = f1score) is :  0.58
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.56      0.78      0.65       200
           1       0.63      0.38      0.48       200

    accuracy                           0.58       400
   macro avg       0.60      0.58      0.56       400
weighted avg       0.60      0.58      0.56       400

F measure at 0 is :  0.65
F measure at 1 is :  0.4750000000000001
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:47:09.506964
end clf.fit at :2019-12-09 08:47:09.522583
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.545625
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[183  17]
 [167  33]]
Accuracy (<> F measure = f1score) is :  0.54
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.52      0.92      0.67       200
           1       0.66      0.17      0.26       200

    accuracy                           0.54       400
   macro avg       0.59      0.54      0.46       400
weighted avg       0.59      0.54      0.46       400

F measure at 0 is :  0.6654545454545455
F measure at 1 is :  0.264
------------ end testing the model ------------
overall_accuracy:  0.567
overall_f_measure:  0.3688046647230321
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-ratio-1.0-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 11)
dataset.head(5):                 0            1                2                3                4                5                6                7            8                9 10
0   '(99.9-199.8]'  '(446-525]'  '(633.6-698.4]'  '(580.2-642.4]'  '(445.5-517.8]'  '(601.8-657.2]'  '(559.2-617.9]'  '(463.9-483.2]'  '(485-500]'   '(-inf-472.1]'  0
1  '(399.6-499.5]'  '(288-367]'    '(439.2-504]'    '(518-580.2]'  '(300.9-373.2]'    '(435.6-491]'  '(441.8-500.5]'  '(483.2-502.5]'  '(485-500]'  '(475.4-476.5]'  0
2  '(499.5-599.4]'  '(604-683]'    '(439.2-504]'  '(393.6-455.8]'  '(590.1-662.4]'    '(435.6-491]'  '(500.5-559.2]'  '(521.8-541.1]'  '(485-500]'  '(475.4-476.5]'  0
3  '(599.4-699.3]'  '(525-604]'  '(374.4-439.2]'  '(331.4-393.6]'  '(517.8-590.1]'  '(380.2-435.6]'  '(441.8-500.5]'  '(502.5-521.8]'  '(485-500]'  '(475.4-476.5]'  1
4  '(399.6-499.5]'  '(367-446]'  '(374.4-439.2]'    '(455.8-518]'  '(373.2-445.5]'  '(380.2-435.6]'  '(500.5-559.2]'  '(502.5-521.8]'  '(455-470]'  '(477.6-478.7]'  1
X_binary.shape:  (2000, 100)
start clf.fit at :2019-12-09 08:47:09.671613
end clf.fit at :2019-12-09 08:49:32.474896
clf.best_params:  {'C': 32, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.70625
clf.best_estimator_:  SVC(C=32, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[150  50]
 [ 58 142]]
Accuracy (<> F measure = f1score) is :  0.73
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.72      0.75      0.74       200
           1       0.74      0.71      0.72       200

    accuracy                           0.73       400
   macro avg       0.73      0.73      0.73       400
weighted avg       0.73      0.73      0.73       400

F measure at 0 is :  0.7352941176470588
F measure at 1 is :  0.7244897959183674
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:49:32.574882
end clf.fit at :2019-12-09 08:51:53.863151
clf.best_params:  {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.7050000000000001
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[137  63]
 [ 57 143]]
Accuracy (<> F measure = f1score) is :  0.7
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.71      0.69      0.70       200
           1       0.69      0.71      0.70       200

    accuracy                           0.70       400
   macro avg       0.70      0.70      0.70       400
weighted avg       0.70      0.70      0.70       400

F measure at 0 is :  0.6954314720812182
F measure at 1 is :  0.7044334975369458
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:51:53.972502
end clf.fit at :2019-12-09 08:54:15.082406
clf.best_params:  {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.710625
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[140  60]
 [ 63 137]]
Accuracy (<> F measure = f1score) is :  0.6925
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.69      0.70      0.69       200
           1       0.70      0.69      0.69       200

    accuracy                           0.69       400
   macro avg       0.69      0.69      0.69       400
weighted avg       0.69      0.69      0.69       400

F measure at 0 is :  0.6947890818858561
F measure at 1 is :  0.690176322418136
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:54:15.201525
end clf.fit at :2019-12-09 08:56:37.644083
clf.best_params:  {'C': 8, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.698125
clf.best_estimator_:  SVC(C=8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[154  46]
 [ 66 134]]
Accuracy (<> F measure = f1score) is :  0.72
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.70      0.77      0.73       200
           1       0.74      0.67      0.71       200

    accuracy                           0.72       400
   macro avg       0.72      0.72      0.72       400
weighted avg       0.72      0.72      0.72       400

F measure at 0 is :  0.7333333333333333
F measure at 1 is :  0.7052631578947369
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:56:37.753432
end clf.fit at :2019-12-09 08:58:58.911481
clf.best_params:  {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.70375
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[144  56]
 [ 70 130]]
Accuracy (<> F measure = f1score) is :  0.685
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.67      0.72      0.70       200
           1       0.70      0.65      0.67       200

    accuracy                           0.69       400
   macro avg       0.69      0.69      0.68       400
weighted avg       0.69      0.69      0.68       400

F measure at 0 is :  0.6956521739130436
F measure at 1 is :  0.6735751295336787
------------ end testing the model ------------
overall_accuracy:  0.7055
overall_f_measure:  0.6996430392656807
start clf.fit at :2019-12-09 08:58:59.032654
end clf.fit at :2019-12-09 08:58:59.048275
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5956250000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[180  20]
 [143  57]]
Accuracy (<> F measure = f1score) is :  0.5925
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.56      0.90      0.69       200
           1       0.74      0.28      0.41       200

    accuracy                           0.59       400
   macro avg       0.65      0.59      0.55       400
weighted avg       0.65      0.59      0.55       400

F measure at 0 is :  0.6883365200764818
F measure at 1 is :  0.411552346570397
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:58:59.051334
end clf.fit at :2019-12-09 08:58:59.066980
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5700000000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[188  12]
 [154  46]]
Accuracy (<> F measure = f1score) is :  0.585
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.55      0.94      0.69       200
           1       0.79      0.23      0.36       200

    accuracy                           0.58       400
   macro avg       0.67      0.58      0.53       400
weighted avg       0.67      0.58      0.53       400

F measure at 0 is :  0.6937269372693726
F measure at 1 is :  0.35658914728682173
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:58:59.066980
end clf.fit at :2019-12-09 08:58:59.082601
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.590625
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[184  16]
 [147  53]]
Accuracy (<> F measure = f1score) is :  0.5925
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.56      0.92      0.69       200
           1       0.77      0.27      0.39       200

    accuracy                           0.59       400
   macro avg       0.66      0.59      0.54       400
weighted avg       0.66      0.59      0.54       400

F measure at 0 is :  0.6930320150659134
F measure at 1 is :  0.3940520446096655
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:58:59.098223
end clf.fit at :2019-12-09 08:58:59.098223
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5518750000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[187  13]
 [172  28]]
Accuracy (<> F measure = f1score) is :  0.5375
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.52      0.94      0.67       200
           1       0.68      0.14      0.23       200

    accuracy                           0.54       400
   macro avg       0.60      0.54      0.45       400
weighted avg       0.60      0.54      0.45       400

F measure at 0 is :  0.6690518783542039
F measure at 1 is :  0.23236514522821577
------------ end testing the model ------------
start clf.fit at :2019-12-09 08:58:59.113844
end clf.fit at :2019-12-09 08:58:59.129466
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.573125
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[178  22]
 [158  42]]
Accuracy (<> F measure = f1score) is :  0.55
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.53      0.89      0.66       200
           1       0.66      0.21      0.32       200

    accuracy                           0.55       400
   macro avg       0.59      0.55      0.49       400
weighted avg       0.59      0.55      0.49       400

F measure at 0 is :  0.664179104477612
F measure at 1 is :  0.31818181818181823
------------ end testing the model ------------
overall_accuracy:  0.5715
overall_f_measure:  0.34530175706646293
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-relevance-0.5-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 6)
dataset.head(5):                 0            1                2                3                4  5
0  '(468.6-490.5]'  '(500-517]'  '(460.9-473.2]'  '(486.4-491.3]'  '(478.6-479.4]'  0
1  '(446.7-468.6]'  '(483-500]'  '(497.8-510.1]'  '(491.3-496.2]'    '(476.2-477]'  0
2  '(534.3-556.2]'  '(483-500]'  '(497.8-510.1]'  '(476.6-481.5]'    '(476.2-477]'  0
3  '(490.5-512.4]'  '(483-500]'  '(485.5-497.8]'  '(471.7-476.6]'    '(476.2-477]'  1
4  '(490.5-512.4]'  '(449-466]'  '(473.2-485.5]'  '(476.6-481.5]'  '(477.8-478.6]'  1
X_binary.shape:  (2000, 49)
start clf.fit at :2019-12-09 08:58:59.231268
end clf.fit at :2019-12-09 09:01:30.338315
clf.best_params:  {'C': 0.03125, 'gamma': 2, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.505625
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf', max_iter=-1,
    probability=False, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[  8 192]
 [  6 194]]
Accuracy (<> F measure = f1score) is :  0.505
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.57      0.04      0.07       200
           1       0.50      0.97      0.66       200

    accuracy                           0.51       400
   macro avg       0.54      0.51      0.37       400
weighted avg       0.54      0.51      0.37       400

F measure at 0 is :  0.07476635514018691
F measure at 1 is :  0.6621160409556314
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:01:30.410567
end clf.fit at :2019-12-09 09:04:04.315241
clf.best_params:  {'C': 32768, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.529375
clf.best_estimator_:  SVC(C=32768, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[112  88]
 [ 94 106]]
Accuracy (<> F measure = f1score) is :  0.545
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.54      0.56      0.55       200
           1       0.55      0.53      0.54       200

    accuracy                           0.55       400
   macro avg       0.55      0.55      0.54       400
weighted avg       0.55      0.55      0.54       400

F measure at 0 is :  0.5517241379310345
F measure at 1 is :  0.5380710659898477
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:04:04.379339
end clf.fit at :2019-12-09 09:06:33.803155
clf.best_params:  {'C': 32768, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.535
clf.best_estimator_:  SVC(C=32768, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[101  99]
 [103  97]]
Accuracy (<> F measure = f1score) is :  0.495
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.51      0.50       200
           1       0.49      0.48      0.49       200

    accuracy                           0.49       400
   macro avg       0.49      0.49      0.49       400
weighted avg       0.49      0.49      0.49       400

F measure at 0 is :  0.5000000000000001
F measure at 1 is :  0.4898989898989899
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:06:33.865639
end clf.fit at :2019-12-09 09:09:02.401326
clf.best_params:  {'C': 2048, 'gamma': 3.0517578125e-05, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.52375
clf.best_estimator_:  SVC(C=2048, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=3.0517578125e-05,
    kernel='rbf', max_iter=-1, probability=False, random_state=None,
    shrinking=True, tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[117  83]
 [115  85]]
Accuracy (<> F measure = f1score) is :  0.505
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.58      0.54       200
           1       0.51      0.42      0.46       200

    accuracy                           0.51       400
   macro avg       0.51      0.51      0.50       400
weighted avg       0.51      0.51      0.50       400

F measure at 0 is :  0.5416666666666666
F measure at 1 is :  0.4619565217391304
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:09:02.481850
end clf.fit at :2019-12-09 09:11:28.325702
clf.best_params:  {'C': 8192, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.520625
clf.best_estimator_:  SVC(C=8192, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[118  82]
 [106  94]]
Accuracy (<> F measure = f1score) is :  0.53
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.53      0.59      0.56       200
           1       0.53      0.47      0.50       200

    accuracy                           0.53       400
   macro avg       0.53      0.53      0.53       400
weighted avg       0.53      0.53      0.53       400

F measure at 0 is :  0.5566037735849056
F measure at 1 is :  0.5
------------ end testing the model ------------
overall_accuracy:  0.516
overall_f_measure:  0.5433962264150943
start clf.fit at :2019-12-09 09:11:28.378106
end clf.fit at :2019-12-09 09:11:28.393725
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.499375
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[158  42]
 [154  46]]
Accuracy (<> F measure = f1score) is :  0.51
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.79      0.62       200
           1       0.52      0.23      0.32       200

    accuracy                           0.51       400
   macro avg       0.51      0.51      0.47       400
weighted avg       0.51      0.51      0.47       400

F measure at 0 is :  0.6171875
F measure at 1 is :  0.3194444444444445
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:11:28.409349
end clf.fit at :2019-12-09 09:11:28.409349
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.51625
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[124  76]
 [140  60]]
Accuracy (<> F measure = f1score) is :  0.46
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.47      0.62      0.53       200
           1       0.44      0.30      0.36       200

    accuracy                           0.46       400
   macro avg       0.46      0.46      0.45       400
weighted avg       0.46      0.46      0.45       400

F measure at 0 is :  0.5344827586206896
F measure at 1 is :  0.35714285714285715
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:11:28.424964
end clf.fit at :2019-12-09 09:11:28.424964
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5112499999999999
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 11 189]
 [  8 192]]
Accuracy (<> F measure = f1score) is :  0.5075
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.58      0.06      0.10       200
           1       0.50      0.96      0.66       200

    accuracy                           0.51       400
   macro avg       0.54      0.51      0.38       400
weighted avg       0.54      0.51      0.38       400

F measure at 0 is :  0.10045662100456619
F measure at 1 is :  0.6609294320137693
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:11:28.440591
end clf.fit at :2019-12-09 09:11:28.456181
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.496875
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[167  33]
 [177  23]]
Accuracy (<> F measure = f1score) is :  0.475
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.49      0.83      0.61       200
           1       0.41      0.12      0.18       200

    accuracy                           0.48       400
   macro avg       0.45      0.47      0.40       400
weighted avg       0.45      0.47      0.40       400

F measure at 0 is :  0.613970588235294
F measure at 1 is :  0.1796875
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:11:28.456181
end clf.fit at :2019-12-09 09:11:28.471803
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.501875
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[194   6]
 [190  10]]
Accuracy (<> F measure = f1score) is :  0.51
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.97      0.66       200
           1       0.62      0.05      0.09       200

    accuracy                           0.51       400
   macro avg       0.57      0.51      0.38       400
weighted avg       0.57      0.51      0.38       400

F measure at 0 is :  0.6643835616438356
F measure at 1 is :  0.09259259259259259
------------ end testing the model ------------
overall_accuracy:  0.4925
overall_f_measure:  0.394752534287418
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-relevance-0.6-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 6)
dataset.head(5):                 0                1                2                3                4  5
0    '(510-533.2]'  '(457.6-476.5]'    '(495-508.8]'    '(476-484.2]'  '(477.5-481.6]'  0
1  '(463.6-486.8]'  '(457.6-476.5]'    '(481.2-495]'  '(451.4-459.6]'  '(477.5-481.6]'  0
2  '(533.2-556.4]'  '(438.7-457.6]'  '(508.8-522.6]'    '(467.8-476]'  '(485.7-489.8]'  0
3  '(463.6-486.8]'  '(457.6-476.5]'    '(495-508.8]'    '(476-484.2]'  '(477.5-481.6]'  1
4    '(486.8-510]'  '(495.4-514.3]'  '(508.8-522.6]'    '(476-484.2]'  '(473.4-477.5]'  1
X_binary.shape:  (2000, 50)
start clf.fit at :2019-12-09 09:11:28.579623
end clf.fit at :2019-12-09 09:13:49.114376
clf.best_params:  {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.520625
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[105  95]
 [104  96]]
Accuracy (<> F measure = f1score) is :  0.5025
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.53      0.51       200
           1       0.50      0.48      0.49       200

    accuracy                           0.50       400
   macro avg       0.50      0.50      0.50       400
weighted avg       0.50      0.50      0.50       400

F measure at 0 is :  0.5134474327628362
F measure at 1 is :  0.4910485933503836
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:13:49.208095
end clf.fit at :2019-12-09 09:16:24.060113
clf.best_params:  {'C': 8192, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.5181250000000001
clf.best_estimator_:  SVC(C=8192, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[102  98]
 [104  96]]
Accuracy (<> F measure = f1score) is :  0.495
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.51      0.50       200
           1       0.49      0.48      0.49       200

    accuracy                           0.49       400
   macro avg       0.49      0.49      0.49       400
weighted avg       0.49      0.49      0.49       400

F measure at 0 is :  0.5024630541871922
F measure at 1 is :  0.4873096446700507
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:16:24.125011
end clf.fit at :2019-12-09 09:18:54.112219
clf.best_params:  {'C': 8192, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.51
clf.best_estimator_:  SVC(C=8192, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 98 102]
 [ 89 111]]
Accuracy (<> F measure = f1score) is :  0.5225
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.52      0.49      0.51       200
           1       0.52      0.56      0.54       200

    accuracy                           0.52       400
   macro avg       0.52      0.52      0.52       400
weighted avg       0.52      0.52      0.52       400

F measure at 0 is :  0.5064599483204134
F measure at 1 is :  0.5375302663438257
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:18:54.168757
end clf.fit at :2019-12-09 09:21:22.295998
clf.best_params:  {'C': 8192, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.5225000000000001
clf.best_estimator_:  SVC(C=8192, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[100 100]
 [106  94]]
Accuracy (<> F measure = f1score) is :  0.485
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.49      0.50      0.49       200
           1       0.48      0.47      0.48       200

    accuracy                           0.48       400
   macro avg       0.48      0.48      0.48       400
weighted avg       0.48      0.48      0.48       400

F measure at 0 is :  0.49261083743842365
F measure at 1 is :  0.4771573604060913
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:21:22.351519
end clf.fit at :2019-12-09 09:23:44.471829
clf.best_params:  {'C': 0.5, 'gamma': 0.5, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.51375
clf.best_estimator_:  SVC(C=0.5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[118  82]
 [110  90]]
Accuracy (<> F measure = f1score) is :  0.52
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.52      0.59      0.55       200
           1       0.52      0.45      0.48       200

    accuracy                           0.52       400
   macro avg       0.52      0.52      0.52       400
weighted avg       0.52      0.52      0.52       400

F measure at 0 is :  0.5514018691588786
F measure at 1 is :  0.48387096774193555
------------ end testing the model ------------
overall_accuracy:  0.505
overall_f_measure:  0.4959266802443992
start clf.fit at :2019-12-09 09:23:44.539893
end clf.fit at :2019-12-09 09:23:44.555511
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5068750000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[197   3]
 [197   3]]
Accuracy (<> F measure = f1score) is :  0.5
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.98      0.66       200
           1       0.50      0.01      0.03       200

    accuracy                           0.50       400
   macro avg       0.50      0.50      0.35       400
weighted avg       0.50      0.50      0.35       400

F measure at 0 is :  0.6632996632996634
F measure at 1 is :  0.029126213592233007
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:23:44.571082
end clf.fit at :2019-12-09 09:23:44.571082
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.496875
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[200   0]
 [192   8]]
Accuracy (<> F measure = f1score) is :  0.52
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      1.00      0.68       200
           1       1.00      0.04      0.08       200

    accuracy                           0.52       400
   macro avg       0.76      0.52      0.38       400
weighted avg       0.76      0.52      0.38       400

F measure at 0 is :  0.6756756756756758
F measure at 1 is :  0.07692307692307693
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:23:44.586754
end clf.fit at :2019-12-09 09:23:44.602375
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.508125
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[189  11]
 [194   6]]
Accuracy (<> F measure = f1score) is :  0.4875
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.49      0.94      0.65       200
           1       0.35      0.03      0.06       200

    accuracy                           0.49       400
   macro avg       0.42      0.49      0.35       400
weighted avg       0.42      0.49      0.35       400

F measure at 0 is :  0.6483704974271012
F measure at 1 is :  0.05529953917050691
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:23:44.602375
end clf.fit at :2019-12-09 09:23:44.617998
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5043749999999999
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[191   9]
 [192   8]]
Accuracy (<> F measure = f1score) is :  0.4975
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.95      0.66       200
           1       0.47      0.04      0.07       200

    accuracy                           0.50       400
   macro avg       0.48      0.50      0.36       400
weighted avg       0.48      0.50      0.36       400

F measure at 0 is :  0.6552315608919382
F measure at 1 is :  0.07373271889400922
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:23:44.633614
end clf.fit at :2019-12-09 09:23:44.633614
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.50125
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[194   6]
 [193   7]]
Accuracy (<> F measure = f1score) is :  0.5025
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.97      0.66       200
           1       0.54      0.04      0.07       200

    accuracy                           0.50       400
   macro avg       0.52      0.50      0.36       400
weighted avg       0.52      0.50      0.36       400

F measure at 0 is :  0.6609880749574106
F measure at 1 is :  0.06572769953051644
------------ end testing the model ------------
overall_accuracy:  0.5015
overall_f_measure:  0.060320452403393024
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-relevance-0.7-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 6)
dataset.head(5):             0              1                2            3                4  5
0  '(515-548]'  '(482-509.5]'  '(508.6-531.4]'  '(486-494]'  '(480.5-486.4]'  0
1  '(482-515]'  '(537-564.5]'  '(485.8-508.6]'  '(478-486]'  '(474.6-480.5]'  0
2  '(482-515]'  '(509.5-537]'    '(440.2-463]'  '(494-502]'  '(474.6-480.5]'  0
3  '(548-581]'  '(454.5-482]'  '(485.8-508.6]'  '(486-494]'  '(474.6-480.5]'  1
4  '(548-581]'  '(454.5-482]'  '(485.8-508.6]'  '(470-478]'  '(474.6-480.5]'  1
X_binary.shape:  (2000, 49)
start clf.fit at :2019-12-09 09:23:44.751461
end clf.fit at :2019-12-09 09:26:12.904207
clf.best_params:  {'C': 2, 'gamma': 8, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.49812500000000004
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=8, kernel='rbf', max_iter=-1,
    probability=False, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[170  30]
 [173  27]]
Accuracy (<> F measure = f1score) is :  0.4925
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.85      0.63       200
           1       0.47      0.14      0.21       200

    accuracy                           0.49       400
   macro avg       0.48      0.49      0.42       400
weighted avg       0.48      0.49      0.42       400

F measure at 0 is :  0.6261510128913444
F measure at 1 is :  0.21011673151750973
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:26:12.959015
end clf.fit at :2019-12-09 09:28:44.306549
clf.best_params:  {'C': 0.03125, 'gamma': 0.5, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.5125
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[132  68]
 [153  47]]
Accuracy (<> F measure = f1score) is :  0.4475
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.46      0.66      0.54       200
           1       0.41      0.23      0.30       200

    accuracy                           0.45       400
   macro avg       0.44      0.45      0.42       400
weighted avg       0.44      0.45      0.42       400

F measure at 0 is :  0.5443298969072164
F measure at 1 is :  0.2984126984126984
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:28:44.386182
end clf.fit at :2019-12-09 09:31:20.150089
clf.best_params:  {'C': 0.03125, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.5025000000000001
clf.best_estimator_:  SVC(C=0.03125, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[118  82]
 [137  63]]
Accuracy (<> F measure = f1score) is :  0.4525
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.46      0.59      0.52       200
           1       0.43      0.32      0.37       200

    accuracy                           0.45       400
   macro avg       0.45      0.45      0.44       400
weighted avg       0.45      0.45      0.44       400

F measure at 0 is :  0.5186813186813187
F measure at 1 is :  0.3652173913043478
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:31:20.217867
end clf.fit at :2019-12-09 09:33:45.806831
clf.best_params:  {'C': 128, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.514375
clf.best_estimator_:  SVC(C=128, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[100 100]
 [114  86]]
Accuracy (<> F measure = f1score) is :  0.465
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.47      0.50      0.48       200
           1       0.46      0.43      0.45       200

    accuracy                           0.47       400
   macro avg       0.46      0.46      0.46       400
weighted avg       0.46      0.47      0.46       400

F measure at 0 is :  0.4830917874396135
F measure at 1 is :  0.44559585492227977
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:33:45.869317
end clf.fit at :2019-12-09 09:36:11.202051
clf.best_params:  {'C': 32, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.513125
clf.best_estimator_:  SVC(C=32, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 82 118]
 [121  79]]
Accuracy (<> F measure = f1score) is :  0.4025
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.40      0.41      0.41       200
           1       0.40      0.40      0.40       200

    accuracy                           0.40       400
   macro avg       0.40      0.40      0.40       400
weighted avg       0.40      0.40      0.40       400

F measure at 0 is :  0.40694789081885857
F measure at 1 is :  0.3979848866498741
------------ end testing the model ------------
overall_accuracy:  0.452
overall_f_measure:  0.3552941176470588
start clf.fit at :2019-12-09 09:36:11.277184
end clf.fit at :2019-12-09 09:36:11.277184
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5037499999999999
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[  8 192]
 [ 12 188]]
Accuracy (<> F measure = f1score) is :  0.49
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.40      0.04      0.07       200
           1       0.49      0.94      0.65       200

    accuracy                           0.49       400
   macro avg       0.45      0.49      0.36       400
weighted avg       0.45      0.49      0.36       400

F measure at 0 is :  0.07272727272727272
F measure at 1 is :  0.6482758620689655
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:36:11.292803
end clf.fit at :2019-12-09 09:36:11.292803
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.501875
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[  5 195]
 [  6 194]]
Accuracy (<> F measure = f1score) is :  0.4975
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.45      0.03      0.05       200
           1       0.50      0.97      0.66       200

    accuracy                           0.50       400
   macro avg       0.48      0.50      0.35       400
weighted avg       0.48      0.50      0.35       400

F measure at 0 is :  0.047393364928909956
F measure at 1 is :  0.6587436332767402
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:36:11.308429
end clf.fit at :2019-12-09 09:36:11.324058
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.49437499999999995
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 14 186]
 [  6 194]]
Accuracy (<> F measure = f1score) is :  0.52
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.70      0.07      0.13       200
           1       0.51      0.97      0.67       200

    accuracy                           0.52       400
   macro avg       0.61      0.52      0.40       400
weighted avg       0.61      0.52      0.40       400

F measure at 0 is :  0.1272727272727273
F measure at 1 is :  0.6689655172413793
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:36:11.324058
end clf.fit at :2019-12-09 09:36:11.339647
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.4931249999999999
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[  7 193]
 [  4 196]]
Accuracy (<> F measure = f1score) is :  0.5075
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.64      0.04      0.07       200
           1       0.50      0.98      0.67       200

    accuracy                           0.51       400
   macro avg       0.57      0.51      0.37       400
weighted avg       0.57      0.51      0.37       400

F measure at 0 is :  0.06635071090047394
F measure at 1 is :  0.66553480475382
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:36:11.355321
end clf.fit at :2019-12-09 09:36:11.355321
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.50125
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[  5 195]
 [  6 194]]
Accuracy (<> F measure = f1score) is :  0.4975
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.45      0.03      0.05       200
           1       0.50      0.97      0.66       200

    accuracy                           0.50       400
   macro avg       0.48      0.50      0.35       400
weighted avg       0.48      0.50      0.35       400

F measure at 0 is :  0.047393364928909956
F measure at 1 is :  0.6587436332767402
------------ end testing the model ------------
overall_accuracy:  0.5025
overall_f_measure:  0.6600614964127093
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-relevance-0.8-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 7)
dataset.head(5):                 0                1                2                3                4                5  6
0   '(99.9-199.8]'  '(560.6-587.4]'   '(-inf-386.8]'    '(497-512.2]'  '(460.9-473.2]'  '(473.8-475.4]'  0
1  '(399.6-499.5]'  '(399.8-426.6]'    '(494-520.8]'  '(512.2-527.4]'  '(497.8-510.1]'    '(475.4-477]'  0
2  '(499.5-599.4]'  '(560.6-587.4]'  '(440.4-467.2]'  '(451.4-466.6]'  '(497.8-510.1]'  '(473.8-475.4]'  0
3  '(599.4-699.3]'  '(453.4-480.2]'  '(413.6-440.4]'    '(497-512.2]'  '(485.5-497.8]'  '(470.6-472.2]'  1
4  '(399.6-499.5]'  '(533.8-560.6]'    '(494-520.8]'    '(497-512.2]'  '(473.2-485.5]'  '(481.8-483.4]'  1
X_binary.shape:  (2000, 60)
start clf.fit at :2019-12-09 09:36:11.470568
end clf.fit at :2019-12-09 09:38:31.909265
clf.best_params:  {'C': 8, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.565625
clf.best_estimator_:  SVC(C=8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[121  79]
 [103  97]]
Accuracy (<> F measure = f1score) is :  0.545
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.54      0.60      0.57       200
           1       0.55      0.48      0.52       200

    accuracy                           0.55       400
   macro avg       0.55      0.54      0.54       400
weighted avg       0.55      0.55      0.54       400

F measure at 0 is :  0.570754716981132
F measure at 1 is :  0.5159574468085106
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:38:31.973552
end clf.fit at :2019-12-09 09:40:51.008993
clf.best_params:  {'C': 2, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.553125
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[135  65]
 [105  95]]
Accuracy (<> F measure = f1score) is :  0.575
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.56      0.68      0.61       200
           1       0.59      0.47      0.53       200

    accuracy                           0.57       400
   macro avg       0.58      0.57      0.57       400
weighted avg       0.58      0.57      0.57       400

F measure at 0 is :  0.6136363636363636
F measure at 1 is :  0.5277777777777778
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:40:51.092980
end clf.fit at :2019-12-09 09:43:10.837369
clf.best_params:  {'C': 512, 'gamma': 0.00048828125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.5625
clf.best_estimator_:  SVC(C=512, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.00048828125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[129  71]
 [104  96]]
Accuracy (<> F measure = f1score) is :  0.5625
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.55      0.65      0.60       200
           1       0.57      0.48      0.52       200

    accuracy                           0.56       400
   macro avg       0.56      0.56      0.56       400
weighted avg       0.56      0.56      0.56       400

F measure at 0 is :  0.5958429561200924
F measure at 1 is :  0.5231607629427792
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:43:10.915495
end clf.fit at :2019-12-09 09:45:33.168637
clf.best_params:  {'C': 8, 'gamma': 0.5, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.540625
clf.best_estimator_:  SVC(C=8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[100 100]
 [ 90 110]]
Accuracy (<> F measure = f1score) is :  0.525
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.53      0.50      0.51       200
           1       0.52      0.55      0.54       200

    accuracy                           0.53       400
   macro avg       0.53      0.53      0.52       400
weighted avg       0.53      0.53      0.52       400

F measure at 0 is :  0.5128205128205129
F measure at 1 is :  0.5365853658536585
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:45:33.254834
end clf.fit at :2019-12-09 09:47:50.052296
clf.best_params:  {'C': 32, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.559375
clf.best_estimator_:  SVC(C=32, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[136  64]
 [129  71]]
Accuracy (<> F measure = f1score) is :  0.5175
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.68      0.58       200
           1       0.53      0.35      0.42       200

    accuracy                           0.52       400
   macro avg       0.52      0.52      0.50       400
weighted avg       0.52      0.52      0.50       400

F measure at 0 is :  0.5849462365591398
F measure at 1 is :  0.4238805970149253
------------ end testing the model ------------
overall_accuracy:  0.545
overall_f_measure:  0.5075757575757576
start clf.fit at :2019-12-09 09:47:50.131523
end clf.fit at :2019-12-09 09:47:50.147145
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.526875
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[190  10]
 [172  28]]
Accuracy (<> F measure = f1score) is :  0.545
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.52      0.95      0.68       200
           1       0.74      0.14      0.24       200

    accuracy                           0.55       400
   macro avg       0.63      0.54      0.46       400
weighted avg       0.63      0.55      0.46       400

F measure at 0 is :  0.6761565836298933
F measure at 1 is :  0.23529411764705885
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:47:50.162767
end clf.fit at :2019-12-09 09:47:50.162767
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.519375
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[197   3]
 [192   8]]
Accuracy (<> F measure = f1score) is :  0.5125
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.98      0.67       200
           1       0.73      0.04      0.08       200

    accuracy                           0.51       400
   macro avg       0.62      0.51      0.37       400
weighted avg       0.62      0.51      0.37       400

F measure at 0 is :  0.66893039049236
F measure at 1 is :  0.07582938388625592
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:47:50.178384
end clf.fit at :2019-12-09 09:47:50.194016
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.544375
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[189  11]
 [170  30]]
Accuracy (<> F measure = f1score) is :  0.5475
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.53      0.94      0.68       200
           1       0.73      0.15      0.25       200

    accuracy                           0.55       400
   macro avg       0.63      0.55      0.46       400
weighted avg       0.63      0.55      0.46       400

F measure at 0 is :  0.6762075134168158
F measure at 1 is :  0.24896265560165975
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:47:50.194016
end clf.fit at :2019-12-09 09:47:50.209631
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5337500000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[185  15]
 [176  24]]
Accuracy (<> F measure = f1score) is :  0.5225
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.93      0.66       200
           1       0.62      0.12      0.20       200

    accuracy                           0.52       400
   macro avg       0.56      0.52      0.43       400
weighted avg       0.56      0.52      0.43       400

F measure at 0 is :  0.6595365418894831
F measure at 1 is :  0.20083682008368203
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:47:50.209631
end clf.fit at :2019-12-09 09:47:50.236926
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5175000000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[189  11]
 [191   9]]
Accuracy (<> F measure = f1score) is :  0.495
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.50      0.94      0.65       200
           1       0.45      0.04      0.08       200

    accuracy                           0.49       400
   macro avg       0.47      0.49      0.37       400
weighted avg       0.47      0.49      0.37       400

F measure at 0 is :  0.6517241379310345
F measure at 1 is :  0.08181818181818182
------------ end testing the model ------------
overall_accuracy:  0.5245
overall_f_measure:  0.17232375979112272
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-relevance-0.9-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 9)
dataset.head(5):                 0            1                2                3            4            5                6            7  8
0   '(99.9-199.8]'  '(446-525]'  '(633.6-698.4]'  '(580.2-642.4]'  '(492-520]'  '(491-518]'    '(471.8-485]'  '(476-479]'  0
1  '(399.6-499.5]'  '(288-367]'    '(439.2-504]'    '(518-580.2]'  '(436-464]'  '(518-545]'    '(471.8-485]'  '(485-488]'  0
2  '(499.5-599.4]'  '(604-683]'    '(439.2-504]'  '(393.6-455.8]'  '(436-464]'  '(410-437]'    '(485-498.2]'  '(479-482]'  0
3  '(599.4-699.3]'  '(525-604]'  '(374.4-439.2]'  '(331.4-393.6]'  '(492-520]'  '(518-545]'  '(498.2-511.4]'  '(482-485]'  1
4  '(399.6-499.5]'  '(367-446]'  '(374.4-439.2]'    '(455.8-518]'  '(520-548]'  '(437-464]'    '(485-498.2]'  '(476-479]'  1
X_binary.shape:  (2000, 80)
start clf.fit at :2019-12-09 09:47:50.365040
end clf.fit at :2019-12-09 09:50:03.027300
clf.best_params:  {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.658125
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[126  74]
 [ 66 134]]
Accuracy (<> F measure = f1score) is :  0.65
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.66      0.63      0.64       200
           1       0.64      0.67      0.66       200

    accuracy                           0.65       400
   macro avg       0.65      0.65      0.65       400
weighted avg       0.65      0.65      0.65       400

F measure at 0 is :  0.6428571428571429
F measure at 1 is :  0.6568627450980393
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:50:03.122766
end clf.fit at :2019-12-09 09:52:13.268519
clf.best_params:  {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.66875
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[143  57]
 [ 75 125]]
Accuracy (<> F measure = f1score) is :  0.67
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.66      0.71      0.68       200
           1       0.69      0.62      0.65       200

    accuracy                           0.67       400
   macro avg       0.67      0.67      0.67       400
weighted avg       0.67      0.67      0.67       400

F measure at 0 is :  0.6842105263157894
F measure at 1 is :  0.6544502617801048
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:52:13.350431
end clf.fit at :2019-12-09 09:54:25.001223
clf.best_params:  {'C': 128, 'gamma': 0.0078125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.6625
clf.best_estimator_:  SVC(C=128, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[133  67]
 [ 73 127]]
Accuracy (<> F measure = f1score) is :  0.65
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.65      0.67      0.66       200
           1       0.65      0.64      0.64       200

    accuracy                           0.65       400
   macro avg       0.65      0.65      0.65       400
weighted avg       0.65      0.65      0.65       400

F measure at 0 is :  0.6551724137931035
F measure at 1 is :  0.6446700507614213
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:54:25.084100
end clf.fit at :2019-12-09 09:56:37.578493
clf.best_params:  {'C': 32, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.6525000000000001
clf.best_estimator_:  SVC(C=32, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[143  57]
 [ 71 129]]
Accuracy (<> F measure = f1score) is :  0.68
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.67      0.71      0.69       200
           1       0.69      0.65      0.67       200

    accuracy                           0.68       400
   macro avg       0.68      0.68      0.68       400
weighted avg       0.68      0.68      0.68       400

F measure at 0 is :  0.6908212560386473
F measure at 1 is :  0.6683937823834197
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:56:37.657949
end clf.fit at :2019-12-09 09:58:50.850786
clf.best_params:  {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.6599999999999999
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[145  55]
 [ 72 128]]
Accuracy (<> F measure = f1score) is :  0.6825
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.67      0.72      0.70       200
           1       0.70      0.64      0.67       200

    accuracy                           0.68       400
   macro avg       0.68      0.68      0.68       400
weighted avg       0.68      0.68      0.68       400

F measure at 0 is :  0.6954436450839329
F measure at 1 is :  0.6684073107049608
------------ end testing the model ------------
overall_accuracy:  0.6665
overall_f_measure:  0.65847414234511
start clf.fit at :2019-12-09 09:58:50.943038
end clf.fit at :2019-12-09 09:58:50.958694
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5431250000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[193   7]
 [162  38]]
Accuracy (<> F measure = f1score) is :  0.5775
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.54      0.96      0.70       200
           1       0.84      0.19      0.31       200

    accuracy                           0.58       400
   macro avg       0.69      0.58      0.50       400
weighted avg       0.69      0.58      0.50       400

F measure at 0 is :  0.6954954954954955
F measure at 1 is :  0.31020408163265306
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:58:50.974316
end clf.fit at :2019-12-09 09:58:50.989938
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.53625
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[195   5]
 [169  31]]
Accuracy (<> F measure = f1score) is :  0.565
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.54      0.97      0.69       200
           1       0.86      0.15      0.26       200

    accuracy                           0.56       400
   macro avg       0.70      0.56      0.48       400
weighted avg       0.70      0.56      0.48       400

F measure at 0 is :  0.6914893617021276
F measure at 1 is :  0.2627118644067797
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:58:50.989938
end clf.fit at :2019-12-09 09:58:51.005560
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5606250000000002
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[185  15]
 [164  36]]
Accuracy (<> F measure = f1score) is :  0.5525
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.53      0.93      0.67       200
           1       0.71      0.18      0.29       200

    accuracy                           0.55       400
   macro avg       0.62      0.55      0.48       400
weighted avg       0.62      0.55      0.48       400

F measure at 0 is :  0.6739526411657559
F measure at 1 is :  0.2868525896414343
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:58:51.005560
end clf.fit at :2019-12-09 09:58:51.021187
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.54375
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[191   9]
 [175  25]]
Accuracy (<> F measure = f1score) is :  0.54
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.52      0.95      0.67       200
           1       0.74      0.12      0.21       200

    accuracy                           0.54       400
   macro avg       0.63      0.54      0.44       400
weighted avg       0.63      0.54      0.44       400

F measure at 0 is :  0.6749116607773851
F measure at 1 is :  0.21367521367521367
------------ end testing the model ------------
start clf.fit at :2019-12-09 09:58:51.036806
end clf.fit at :2019-12-09 09:58:51.036806
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.54125
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[182  18]
 [172  28]]
Accuracy (<> F measure = f1score) is :  0.525
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.51      0.91      0.66       200
           1       0.61      0.14      0.23       200

    accuracy                           0.53       400
   macro avg       0.56      0.53      0.44       400
weighted avg       0.56      0.53      0.44       400

F measure at 0 is :  0.6570397111913359
F measure at 1 is :  0.22764227642276424
------------ end testing the model ------------
overall_accuracy:  0.552
overall_f_measure:  0.2607260726072607
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  madelon-10-disc.arff-relevance-1.0-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (2000, 15)
dataset.head(5):                0            1                2                3                4                5   ...           9            10               11               12               13 14
0   '(99.9-199.8]'  '(446-525]'  '(633.6-698.4]'  '(580.2-642.4]'  '(445.5-517.8]'  '(601.8-657.2]'  ...  '(429-461]'  '(594-641]'    '(491-536.6]'    '(479.2-501]'    '(472.4-483]'  0
1  '(399.6-499.5]'  '(288-367]'    '(439.2-504]'    '(518-580.2]'  '(300.9-373.2]'    '(435.6-491]'  ...  '(525-557]'  '(547-594]'  '(399.8-445.4]'    '(479.2-501]'    '(483-493.6]'  0
2  '(499.5-599.4]'  '(604-683]'    '(439.2-504]'  '(393.6-455.8]'  '(590.1-662.4]'    '(435.6-491]'  ...  '(461-493]'  '(406-453]'  '(536.6-582.2]'  '(457.4-479.2]'    '(472.4-483]'  0
3  '(599.4-699.3]'  '(525-604]'  '(374.4-439.2]'  '(331.4-393.6]'  '(517.8-590.1]'  '(380.2-435.6]'  ...  '(557-589]'  '(453-500]'  '(536.6-582.2]'    '(479.2-501]'  '(493.6-504.2]'  1
4  '(399.6-499.5]'  '(367-446]'  '(374.4-439.2]'    '(455.8-518]'  '(373.2-445.5]'  '(380.2-435.6]'  ...  '(525-557]'  '(453-500]'    '(445.4-491]'    '(479.2-501]'    '(483-493.6]'  1

[5 rows x 15 columns]
X_binary.shape:  (2000, 140)
start clf.fit at :2019-12-09 09:58:51.221126
end clf.fit at :2019-12-09 10:01:46.567597
clf.best_params:  {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.7525
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[153  47]
 [ 47 153]]
Accuracy (<> F measure = f1score) is :  0.765
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.77      0.77      0.77       200
           1       0.77      0.77      0.77       200

    accuracy                           0.77       400
   macro avg       0.77      0.77      0.77       400
weighted avg       0.77      0.77      0.77       400

F measure at 0 is :  0.765
F measure at 1 is :  0.765
------------ end testing the model ------------
start clf.fit at :2019-12-09 10:01:46.734881
end clf.fit at :2019-12-09 10:04:42.428957
clf.best_params:  {'C': 8, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.7418750000000001
clf.best_estimator_:  SVC(C=8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[152  48]
 [ 52 148]]
Accuracy (<> F measure = f1score) is :  0.75
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.75      0.76      0.75       200
           1       0.76      0.74      0.75       200

    accuracy                           0.75       400
   macro avg       0.75      0.75      0.75       400
weighted avg       0.75      0.75      0.75       400

F measure at 0 is :  0.7524752475247525
F measure at 1 is :  0.7474747474747474
------------ end testing the model ------------
start clf.fit at :2019-12-09 10:04:42.587516
end clf.fit at :2019-12-09 10:07:38.611093
clf.best_params:  {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.7481249999999999
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[151  49]
 [ 45 155]]
Accuracy (<> F measure = f1score) is :  0.765
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.77      0.76      0.76       200
           1       0.76      0.78      0.77       200

    accuracy                           0.77       400
   macro avg       0.77      0.77      0.76       400
weighted avg       0.77      0.77      0.76       400

F measure at 0 is :  0.7626262626262627
F measure at 1 is :  0.7673267326732675
------------ end testing the model ------------
start clf.fit at :2019-12-09 10:07:38.780959
end clf.fit at :2019-12-09 10:10:33.511808
clf.best_params:  {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.7518749999999998
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[157  43]
 [ 59 141]]
Accuracy (<> F measure = f1score) is :  0.745
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.73      0.79      0.75       200
           1       0.77      0.70      0.73       200

    accuracy                           0.74       400
   macro avg       0.75      0.74      0.74       400
weighted avg       0.75      0.74      0.74       400

F measure at 0 is :  0.7548076923076924
F measure at 1 is :  0.734375
------------ end testing the model ------------
start clf.fit at :2019-12-09 10:10:33.683642
end clf.fit at :2019-12-09 10:13:28.383204
clf.best_params:  {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.735
clf.best_estimator_:  SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[151  49]
 [ 45 155]]
Accuracy (<> F measure = f1score) is :  0.765
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.77      0.76      0.76       200
           1       0.76      0.78      0.77       200

    accuracy                           0.77       400
   macro avg       0.77      0.77      0.76       400
weighted avg       0.77      0.77      0.76       400

F measure at 0 is :  0.7626262626262627
F measure at 1 is :  0.7673267326732675
------------ end testing the model ------------
overall_accuracy:  0.758
overall_f_measure:  0.7565392354124748
start clf.fit at :2019-12-09 10:13:28.555423
end clf.fit at :2019-12-09 10:13:28.571662
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.530625
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 15 185]
 [ 12 188]]
Accuracy (<> F measure = f1score) is :  0.5075
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.56      0.07      0.13       200
           1       0.50      0.94      0.66       200

    accuracy                           0.51       400
   macro avg       0.53      0.51      0.39       400
weighted avg       0.53      0.51      0.39       400

F measure at 0 is :  0.13215859030837004
F measure at 1 is :  0.656195462478185
------------ end testing the model ------------
start clf.fit at :2019-12-09 10:13:28.587599
end clf.fit at :2019-12-09 10:13:28.603221
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.5593750000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  1
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[162  38]
 [124  76]]
Accuracy (<> F measure = f1score) is :  0.595
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.57      0.81      0.67       200
           1       0.67      0.38      0.48       200

    accuracy                           0.59       400
   macro avg       0.62      0.59      0.58       400
weighted avg       0.62      0.59      0.58       400

F measure at 0 is :  0.6666666666666667
F measure at 1 is :  0.48407643312101906
------------ end testing the model ------------
start clf.fit at :2019-12-09 10:13:28.618842
end clf.fit at :2019-12-09 10:13:28.634984
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.539375
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  2
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 25 175]
 [ 10 190]]
Accuracy (<> F measure = f1score) is :  0.5375
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.71      0.12      0.21       200
           1       0.52      0.95      0.67       200

    accuracy                           0.54       400
   macro avg       0.62      0.54      0.44       400
weighted avg       0.62      0.54      0.44       400

F measure at 0 is :  0.2127659574468085
F measure at 1 is :  0.6725663716814159
------------ end testing the model ------------
start clf.fit at :2019-12-09 10:13:28.650858
end clf.fit at :2019-12-09 10:13:28.666479
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.57375
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  3
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[104  96]
 [ 53 147]]
Accuracy (<> F measure = f1score) is :  0.6275
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.66      0.52      0.58       200
           1       0.60      0.73      0.66       200

    accuracy                           0.63       400
   macro avg       0.63      0.63      0.62       400
weighted avg       0.63      0.63      0.62       400

F measure at 0 is :  0.5826330532212886
F measure at 1 is :  0.6636568848758466
------------ end testing the model ------------
start clf.fit at :2019-12-09 10:13:28.685661
end clf.fit at :2019-12-09 10:13:28.696257
clf.best_params:  {'var_smoothing': 1e-09}
clf.best_score_ (ROC-AUC score):  0.6031250000000001
clf.best_estimator_:  GaussianNB(priors=None, var_smoothing=1e-09)
------------ start testing the model ------------
i =  4
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[ 43 157]
 [ 25 175]]
Accuracy (<> F measure = f1score) is :  0.545
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.63      0.21      0.32       200
           1       0.53      0.88      0.66       200

    accuracy                           0.55       400
   macro avg       0.58      0.55      0.49       400
weighted avg       0.58      0.55      0.49       400

F measure at 0 is :  0.32089552238805974
F measure at 1 is :  0.6578947368421053
------------ end testing the model ------------
overall_accuracy:  0.5625
overall_f_measure:  0.6394725999175938
currentDir:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification
file_name:  mushroom.arff-noise-0.5-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (8124, 4)
dataset.head(5):   0  1  2  3
0  c  t  s  p
1  c  t  s  e
2  c  t  s  e
3  c  t  y  p
4  w  f  s  e
Traceback (most recent call last):
  File "Main.py", line 90, in <module>
    X_trains, y_trains, X_tests, y_tests = Preprocessing.get_splitted_dataset_k_fold(config, dataset)
  File "C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification\Preprocessing.py", line 21, in get_splitted_dataset_k_fold
    y = y.astype(np.int32)
ValueError: invalid literal for int() with base 10: 'p'

C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\Python\classification>python Main.py
os.path.abspath(os.curdir):  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection
type(filePath):  <class 'str'>
config.file_paths:  ['C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-noise-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-noise-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-noise-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-noise-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-noise-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-noise-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-ratio-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-ratio-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-ratio-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-ratio-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-ratio-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-ratio-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-relevance-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-relevance-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-relevance-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-relevance-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-relevance-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\ada-10-disc.arff-relevance-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-noise-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-noise-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-noise-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-noise-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-noise-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-noise-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-ratio-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-ratio-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-ratio-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-ratio-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-ratio-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-ratio-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-relevance-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-relevance-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-relevance-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-relevance-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-relevance-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\arcene-10-disc.arff-relevance-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-noise-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-noise-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-noise-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-noise-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-noise-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-noise-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-ratio-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-ratio-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-ratio-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-ratio-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-ratio-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-ratio-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-relevance-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-relevance-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-relevance-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-relevance-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-relevance-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dexter-10-disc.arff-relevance-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-noise-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-noise-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-noise-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-noise-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-noise-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-noise-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-ratio-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-ratio-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-ratio-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-ratio-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-ratio-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-ratio-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-relevance-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-relevance-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-relevance-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-relevance-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-relevance-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\dorothea.sparse.arff-relevance-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-noise-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-noise-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-noise-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-noise-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-noise-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-noise-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-ratio-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-ratio-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-ratio-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-ratio-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-ratio-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-ratio-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-relevance-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-relevance-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-relevance-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-relevance-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-relevance-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\gina-10-disc.arff-relevance-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-noise-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-noise-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-noise-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-noise-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-noise-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-noise-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-ratio-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-ratio-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-ratio-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-ratio-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-ratio-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-ratio-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-relevance-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-relevance-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-relevance-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-relevance-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-relevance-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\hiva.arff-relevance-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-noise-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-noise-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-noise-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-noise-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-noise-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-noise-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-ratio-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-ratio-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-ratio-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-ratio-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-ratio-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-ratio-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-relevance-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-relevance-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-relevance-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-relevance-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-relevance-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\kr-vs-kp.arff-relevance-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-noise-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-noise-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-noise-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-noise-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-noise-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-noise-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-ratio-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-ratio-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-ratio-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-ratio-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-ratio-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-ratio-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-relevance-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-relevance-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-relevance-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-relevance-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-relevance-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\madelon-10-disc.arff-relevance-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-noise-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-noise-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-noise-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-noise-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-noise-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-noise-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-ratio-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-ratio-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-ratio-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-ratio-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-ratio-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-ratio-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-relevance-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-relevance-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-relevance-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-relevance-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-relevance-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\nova.arff-relevance-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-noise-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-noise-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-noise-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-noise-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-noise-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-noise-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-ratio-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-ratio-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-ratio-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-ratio-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-ratio-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-ratio-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-relevance-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-relevance-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-relevance-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-relevance-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-relevance-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\spambase-disc.arff-relevance-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-noise-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-noise-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-noise-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-noise-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-noise-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-noise-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-ratio-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-ratio-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-ratio-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-ratio-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-ratio-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-ratio-1.0-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-relevance-0.5-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-relevance-0.6-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-relevance-0.7-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-relevance-0.8-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-relevance-0.9-bornfs.arff', 'C:\\Users\\bring\\Dropbox\\job hunting\\freelance\\yoshihiro_shin\\BornFS_Experiment_github\\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\\bornfs_datasets\\out\\sylva-10-disc.arff-relevance-1.0-bornfs.arff']
dataset_directory:  C:\Users\bring\Dropbox\job hunting\freelance\yoshihiro_shin\BornFS_Experiment_github\Machine_Learning_Preprocessing_and_Performance_Test_after_Feature_Selection\bornfs_datasets\out\*.arff
the export file ada-10-disc.arff-noise-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file ada-10-disc.arff-noise-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file ada-10-disc.arff-noise-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file ada-10-disc.arff-noise-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file ada-10-disc.arff-noise-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file ada-10-disc.arff-noise-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file ada-10-disc.arff-ratio-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file ada-10-disc.arff-ratio-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file ada-10-disc.arff-ratio-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file ada-10-disc.arff-ratio-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file ada-10-disc.arff-ratio-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file ada-10-disc.arff-ratio-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file ada-10-disc.arff-relevance-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file ada-10-disc.arff-relevance-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file ada-10-disc.arff-relevance-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file ada-10-disc.arff-relevance-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file ada-10-disc.arff-relevance-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file ada-10-disc.arff-relevance-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-noise-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-noise-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-noise-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-noise-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-noise-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-noise-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-ratio-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-ratio-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-ratio-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-ratio-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-ratio-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-ratio-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-relevance-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-relevance-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-relevance-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-relevance-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-relevance-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file arcene-10-disc.arff-relevance-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-noise-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-noise-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-noise-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-noise-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-noise-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-noise-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-ratio-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-ratio-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-ratio-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-ratio-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-ratio-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-ratio-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-relevance-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-relevance-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-relevance-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-relevance-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-relevance-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file dexter-10-disc.arff-relevance-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-noise-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-noise-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-noise-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-noise-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-noise-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-noise-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-ratio-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-ratio-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-ratio-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-ratio-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-ratio-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-ratio-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-relevance-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-relevance-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-relevance-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-relevance-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-relevance-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file dorothea.sparse.arff-relevance-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-noise-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-noise-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-noise-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-noise-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-noise-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-noise-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-ratio-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-ratio-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-ratio-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-ratio-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-ratio-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-ratio-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-relevance-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-relevance-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-relevance-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-relevance-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-relevance-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file gina-10-disc.arff-relevance-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-noise-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-noise-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-noise-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-noise-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-noise-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-noise-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-ratio-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-ratio-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-ratio-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-ratio-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-ratio-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-ratio-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-relevance-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-relevance-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-relevance-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-relevance-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-relevance-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file hiva.arff-relevance-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-noise-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-noise-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-noise-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-noise-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-noise-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-noise-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-ratio-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-ratio-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-ratio-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-ratio-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-ratio-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-ratio-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-relevance-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-relevance-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-relevance-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-relevance-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-relevance-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file kr-vs-kp.arff-relevance-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-noise-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-noise-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-noise-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-noise-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-noise-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-noise-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-ratio-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-ratio-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-ratio-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-ratio-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-ratio-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-ratio-1.0-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-relevance-0.5-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-relevance-0.6-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-relevance-0.7-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-relevance-0.8-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-relevance-0.9-bornfs_test_result.csv already exists. skip the iteration.
the export file madelon-10-disc.arff-relevance-1.0-bornfs_test_result.csv already exists. skip the iteration.
file_name:  nova.arff-noise-0.5-bornfs.arff process start.
type(dataset):  <class 'pandas.core.frame.DataFrame'>
dataset.shape:  (1754, 329)
dataset.head(5):   0    1    2    3    4    5    6    7    8    9    10   11   12   13   14   15   16   17   ...  311  312  313  314  315  316  317  318  319  320  321  322  323  324  325  326  327  328
0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0
1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0
2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    1
3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    1
4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    1

[5 rows x 329 columns]
X_binary.shape:  (1754, 565)
start clf.fit at :2019-12-09 23:53:17.354365
end clf.fit at :2019-12-09 23:58:07.499343
clf.best_params:  {'C': 32, 'gamma': 0.03125, 'kernel': 'rbf'}
clf.best_score_ (ROC-AUC score):  0.7626690391459074
clf.best_estimator_:  SVC(C=32, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
------------ start testing the model ------------
i =  0
type(y_test):  <class 'numpy.ndarray'>
type(y_test[0]):  <class 'numpy.int32'>
type(y_pred):  <class 'numpy.ndarray'>
type(y_pred[0]):  <class 'numpy.int32'>
confusionMatrixResult:  [[230  21]
 [ 61  39]]
Accuracy (<> F measure = f1score) is :  0.7663817663817664
classification_report(y_test, y_pred, output_dict=False):                precision    recall  f1-score   support

           0       0.79      0.92      0.85       251
           1       0.65      0.39      0.49       100

    accuracy                           0.77       351
   macro avg       0.72      0.65      0.67       351
weighted avg       0.75      0.77      0.75       351

F measure at 0 is :  0.8487084870848708
F measure at 1 is :  0.4875
------------ end testing the model ------------
start clf.fit at :2019-12-09 23:58:07.773408
